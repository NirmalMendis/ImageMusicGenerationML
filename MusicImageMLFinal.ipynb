{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q92Tm6vXFoDZ"
   },
   "source": [
    "# **Melody Generation from Images**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rfhk6yjcFz3U"
   },
   "source": [
    "## **Importing Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "lPxzg6bIDSg2"
   },
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "from pickle import load, dump\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import add\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from glob import glob\n",
    "import os\n",
    "from numpy import argmax\n",
    "from music21 import converter, instrument, note, chord, stream, meter,duration, interval, pitch, tempo, midi\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "\n",
    "from os import listdir\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tz9A41rGF6Dz"
   },
   "source": [
    "**Mount Drive**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Pg7609hVEiAt",
    "outputId": "1c5f02b3-03f8-4ee6-f838-3349787dcbd3"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OoZwxlJwhaqj"
   },
   "source": [
    "To include data folder into drive,\n",
    "go to the below link and click on add shortcut to drive\n",
    "https://drive.google.com/drive/folders/1TTg5wH78eE0yR_OHJZTJzF3wGv8t0Q1x?usp=sharing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AqrNGeK7hauV"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MZTgVRCjZLlZ"
   },
   "source": [
    "**Declare Constants**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "h7ocSZhrE84g"
   },
   "outputs": [],
   "source": [
    "#data folder path\n",
    "data_dir = r'E:\\uniSlides\\CS\\Research\\FinalDataset\\FinalData\\unique_2VGG_FINAL\\\\' \n",
    "#midi note and duration separator\n",
    "separator = \"@\"\n",
    "#image classifier model labels\n",
    "label_VGG16 = \"VGG16\"\n",
    "label_InceptionV3 = \"InceptionV3\"\n",
    "#image model currently in use\n",
    "current_ImgModel = label_VGG16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HUe8BlpKGTGo"
   },
   "source": [
    "## **Midi Preprocessing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "11naS350GLmX"
   },
   "source": [
    "Obtain all midi files from folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "I10Oaa7fF-ec"
   },
   "outputs": [],
   "source": [
    "songs = glob(data_dir + 'midi/*.MID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mwLtORNdCJHY"
   },
   "source": [
    "### **Function Definitions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sIneWaoKGYZ1"
   },
   "source": [
    "Define function to convert list to string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "M18_jz4hGbqZ"
   },
   "outputs": [],
   "source": [
    "def listToString(listObj): \n",
    "    \n",
    "    # initialize an empty string\n",
    "    stringText = \"\" \n",
    "    \n",
    "    # traverse in the string  \n",
    "    for element in listObj: \n",
    "        stringText = stringText + \" \" + element  \n",
    "    \n",
    "    # return string  \n",
    "    return stringText "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cpgNP75Nu7x0"
   },
   "source": [
    "Function to transpose a song to C maj if Major or A min if Minor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "KNh0q4sPu67h"
   },
   "outputs": [],
   "source": [
    "def transpose(song):\n",
    "    #Transposes song to C maj/A min\n",
    "\n",
    "    # get key using music21\n",
    "    key = song.analyze(\"key\")\n",
    "    # get interval for transposition. E.g., Bmaj -> Cmaj\n",
    "    if key.mode == \"major\":\n",
    "        intervalSong = interval.Interval(key.tonic, pitch.Pitch(\"C\"))\n",
    "    elif key.mode == \"minor\":\n",
    "        intervalSong = interval.Interval(key.tonic, pitch.Pitch(\"A\"))\n",
    "\n",
    "    # transpose song by calculated interval\n",
    "    tranposed_song = song.transpose(intervalSong)\n",
    "    return tranposed_song"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pMkWtr2DvFhD"
   },
   "source": [
    "Function to check if rests are more than one bar length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "YJ61NfmtvEdG"
   },
   "outputs": [],
   "source": [
    "#function to check if rest duration is acceptables\n",
    "def isRestAcceptable(rest, timeSignature):\n",
    "  #check is time signature denominator is 4\n",
    "  if (timeSignature.denominator == 4):\n",
    "      #if denominator 4, length of one bar is 4 beats\n",
    "      barDuration = timeSignature.numerator \n",
    "  #check is time signature denominator is 8 \n",
    "  elif (timeSignature.denominator == 8):\n",
    "      #if denominator is 8, length of one bar is numerator/2\n",
    "      barDuration = timeSignature.numerator/2.0\n",
    "  #check is time signature denominator is 2\n",
    "  elif (timeSignature.denominator == 2):\n",
    "      #if denominator is 2, length of one bar is numerator * 2\n",
    "      barDuration = timeSignature.numerator * 2.0\n",
    "  #return false if rest duration is greater than 2 bars\n",
    "  if barDuration * 2 < rest.quarterLength:\n",
    "      return False\n",
    "  \n",
    "  return True    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to get bar in which 1st note occurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getStartingBar(score):\n",
    "    for i in range(51):\n",
    "        bar = score.measures(i-1,i)\n",
    "        barflat = bar.flat\n",
    "        for event in barflat:\n",
    "            if isinstance(event, note.Note):\n",
    "                num = i\n",
    "                break\n",
    "        else:\n",
    "            continue\n",
    "        break;\n",
    "    return num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g_HudA1VKVk_"
   },
   "source": [
    "Define function to create midi data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "KxVpHxyiWKwe"
   },
   "outputs": [],
   "source": [
    "def createDatafile():\n",
    "  #create a file named midiData.txt and append\n",
    "  midiData_file = open(data_dir + \"midiData.txt\", \"w\")\n",
    "#iterate over each midi file\n",
    "  print(\"Writing midi data to file...\")\n",
    "  songCount = 0\n",
    "  for file in songs:\n",
    "    print(file)\n",
    "    try:\n",
    "        midi = converter.parse(file) #convert to midi\n",
    "    except:\n",
    "        print(\"Error in parsing \" + str(file))\n",
    "        continue\n",
    "    #midi = midi.stripTies()\n",
    "    #tranpose song\n",
    "    try:\n",
    "        midi = transpose(midi)\n",
    "    except:\n",
    "        print(\"Error in obtaining key for \" + str(file))\n",
    "        continue\n",
    "    #obtain 30 bars\n",
    "    songTempo = ''\n",
    "    try:\n",
    "        firstbar = midi.measures(0,3)\n",
    "        firstbarNotes = firstbar.flat\n",
    "        for element in firstbarNotes:  \n",
    "            if isinstance(element, tempo.MetronomeMark): \n",
    "                songTempo = str(element.number) + separator + \"tempo\"\n",
    "        startBar = getStartingBar(midi)\n",
    "        midi = midi.measures(startBar, startBar + 7)\n",
    "    except Exception as e:\n",
    "      print(\"Error in measures for \" + str(file))\n",
    "      continue\n",
    "    midi = midi.flat #combine all parts and get a single notes part\n",
    "    \n",
    "    songCount += 1\n",
    "    #initialize timeSignature, notes list and count variables\n",
    "    timeSignature = ''\n",
    "    notes = []\n",
    "    #count = 0\n",
    "\n",
    "    #loop over each midi event\n",
    "    #midi events include timesignatures, instruments, notes, rests and chords\n",
    "    for event in midi: \n",
    "      #only obtain 50 events\n",
    "      # if count == 50:\n",
    "      #   break;\n",
    "      # count += 1 #increase count\n",
    "      #check if event is a timeSignature\n",
    "      if isinstance(event, meter.TimeSignature ):\n",
    "        #save time signature to file as '3/4@time'\n",
    "        timeSignature = event.ratioString + separator + \"time\" \n",
    "        timeSignatureEvent = event\n",
    "      #check if event is a note\n",
    "      if isinstance(event, note.Note):\n",
    "        #save note to file as 'C1@0.5' where 'C1' is midi note and '0.5' is the duration\n",
    "        notes.append(str(event.pitch) + separator + str(event.quarterLength))  \n",
    "      #check if event is a chord\n",
    "      elif(isinstance(event, chord.Chord)):\n",
    "        #save chord to file as '1.8.2@0.5' where '1.8.2' are notes in the chord and '0.5' is the duration\n",
    "        notes.append(('.'.join(str(n) for n in event.normalOrder))+ separator + str(event.quarterLength))\n",
    "      #check if event is a rest\n",
    "      elif(isinstance(event, note.Rest)):\n",
    "        #check if rest duration is acceptable\n",
    "        if isRestAcceptable(event, timeSignatureEvent):\n",
    "          #save rest as 'r@0.5' where 'r' indicates that it is a rest and '0.5'  is the duration\n",
    "          notes.append('r' + separator + str(event.quarterLength))\n",
    "\n",
    "    #save the sequence to the file\n",
    "    jpgFilenamesList = glob(data_dir + 'images/' + os.path.basename(file).split('.')[0] + '*.*')\n",
    "    simImageCount = 0\n",
    "    for image in jpgFilenamesList:\n",
    "        simImageCount += 1\n",
    "        #first write the file id which is same as the image id\n",
    "        sequence = os.path.basename(image).split('.')[0] + \" \" + \"<start> \" + songTempo + \" \" + timeSignature + listToString(notes) + \" <end>\" #append <start> and <end> tokens\n",
    "        #if current song is the last in the list, don't add a newline character to the end\n",
    "        if((len(songs)== songs.index(file) +1) and simImageCount == len(jpgFilenamesList)):\n",
    "            pass\n",
    "        else:\n",
    "            sequence = sequence + \"\\n\"\n",
    "        midiData_file.write(sequence)\n",
    "  \n",
    "  print(f\"Finishes writing midi data. {songCount} songs written.\")\n",
    "  #close file\n",
    "  midiData_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zm2h3pq3eqfu"
   },
   "source": [
    "Function to load a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "_BDRlNUneu-X"
   },
   "outputs": [],
   "source": [
    "def load_file(fileName):\n",
    "  #open file in read mode\n",
    "  file = open(fileName, 'r')\n",
    "  #obtain content in file\n",
    "  content = file.read()\n",
    "  #close file\n",
    "  file.close()\n",
    "\n",
    "  return content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JLvq2lMhgH4s"
   },
   "source": [
    "Function to map file content to dict, create vocabulary and obtain max length of a midi sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "eih_IOM7f4mZ"
   },
   "outputs": [],
   "source": [
    "def dict_vocab_maxLength(content):\n",
    "  #initialize dictionary\n",
    "  midiDict = dict()\n",
    "  vocabulary = set()\n",
    "  maxLength = 0\n",
    "  #loop over each line in content -> each midi song is separated by new line\n",
    "  for line in content.split('\\n'):\n",
    "    #split line into tokens by white space\n",
    "    tokens = line.split()\n",
    "    #first token is image id, rest are midi events\n",
    "    imageId, midi = tokens[0], tokens[1:]\n",
    "    #create a list if not created\n",
    "    if imageId not in midiDict:\n",
    "      midiDict[imageId] = list()\n",
    "    midiDict[imageId].append(midi)\n",
    "    #build vocabulary\n",
    "    vocabulary.update(midi)\n",
    "    #store max length\n",
    "    if len(tokens) > maxLength:\n",
    "      maxLength = len(tokens)\n",
    "  #return dict, vocabulary and maxlength\n",
    "  return midiDict, vocabulary, maxLength"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i-jJJ71N8a9F"
   },
   "source": [
    "Function to tokenize vocabulary and return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "wb12L6J8zTh_"
   },
   "outputs": [],
   "source": [
    "def tokenize(vocab):\n",
    "  #filter 50 midi events with low frequency\n",
    "  num_words= len(vocab) - 10\n",
    "  #initialize tokenizer object without any filters\n",
    "  tokenizer = Tokenizer(num_words=num_words, filters='')\n",
    "  #generate tokens\n",
    "  tokenizer.fit_on_texts(vocab)\n",
    "  print(\"Number of tokens: \" + str(len(tokenizer.word_index)))\n",
    "  return tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HEg9f6j9CTJt"
   },
   "source": [
    "### **Midi Preprocessing steps**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tMC_Y17uCiW6"
   },
   "source": [
    "Create a text file with all midi data of all songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MnT6LSxACdlC",
    "outputId": "7fa7207a-0d70-4cef-8ba4-c2352d2f14f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing midi data to file...\n",
      "E:\\uniSlides\\CS\\Research\\FinalDataset\\FinalData\\unique_2VGG_FINAL\\\\midi\\00008.MID\n",
      "E:\\uniSlides\\CS\\Research\\FinalDataset\\FinalData\\unique_2VGG_FINAL\\\\midi\\00009.MID\n",
      "E:\\uniSlides\\CS\\Research\\FinalDataset\\FinalData\\unique_2VGG_FINAL\\\\midi\\00016.MID\n",
      "E:\\uniSlides\\CS\\Research\\FinalDataset\\FinalData\\unique_2VGG_FINAL\\\\midi\\00018.MID\n",
      "E:\\uniSlides\\CS\\Research\\FinalDataset\\FinalData\\unique_2VGG_FINAL\\\\midi\\00021.MID\n",
      "E:\\uniSlides\\CS\\Research\\FinalDataset\\FinalData\\unique_2VGG_FINAL\\\\midi\\00024.MID\n",
      "E:\\uniSlides\\CS\\Research\\FinalDataset\\FinalData\\unique_2VGG_FINAL\\\\midi\\00027.MID\n",
      "E:\\uniSlides\\CS\\Research\\FinalDataset\\FinalData\\unique_2VGG_FINAL\\\\midi\\00028.MID\n",
      "E:\\uniSlides\\CS\\Research\\FinalDataset\\FinalData\\unique_2VGG_FINAL\\\\midi\\00029.MID\n",
      "E:\\uniSlides\\CS\\Research\\FinalDataset\\FinalData\\unique_2VGG_FINAL\\\\midi\\00030.MID\n",
      "E:\\uniSlides\\CS\\Research\\FinalDataset\\FinalData\\unique_2VGG_FINAL\\\\midi\\00033.MID\n",
      "E:\\uniSlides\\CS\\Research\\FinalDataset\\FinalData\\unique_2VGG_FINAL\\\\midi\\00034.MID\n",
      "E:\\uniSlides\\CS\\Research\\FinalDataset\\FinalData\\unique_2VGG_FINAL\\\\midi\\00036.MID\n",
      "E:\\uniSlides\\CS\\Research\\FinalDataset\\FinalData\\unique_2VGG_FINAL\\\\midi\\00037.MID\n",
      "E:\\uniSlides\\CS\\Research\\FinalDataset\\FinalData\\unique_2VGG_FINAL\\\\midi\\00038.MID\n",
      "E:\\uniSlides\\CS\\Research\\FinalDataset\\FinalData\\unique_2VGG_FINAL\\\\midi\\00040.MID\n",
      "E:\\uniSlides\\CS\\Research\\FinalDataset\\FinalData\\unique_2VGG_FINAL\\\\midi\\00051.MID\n",
      "E:\\uniSlides\\CS\\Research\\FinalDataset\\FinalData\\unique_2VGG_FINAL\\\\midi\\00053.MID\n",
      "E:\\uniSlides\\CS\\Research\\FinalDataset\\FinalData\\unique_2VGG_FINAL\\\\midi\\00054.MID\n",
      "E:\\uniSlides\\CS\\Research\\FinalDataset\\FinalData\\unique_2VGG_FINAL\\\\midi\\00055.MID\n",
      "E:\\uniSlides\\CS\\Research\\FinalDataset\\FinalData\\unique_2VGG_FINAL\\\\midi\\00056.MID\n",
      "E:\\uniSlides\\CS\\Research\\FinalDataset\\FinalData\\unique_2VGG_FINAL\\\\midi\\00057.MID\n",
      "E:\\uniSlides\\CS\\Research\\FinalDataset\\FinalData\\unique_2VGG_FINAL\\\\midi\\00059.MID\n",
      "E:\\uniSlides\\CS\\Research\\FinalDataset\\FinalData\\unique_2VGG_FINAL\\\\midi\\00063.MID\n",
      "E:\\uniSlides\\CS\\Research\\FinalDataset\\FinalData\\unique_2VGG_FINAL\\\\midi\\00065.MID\n",
      "E:\\uniSlides\\CS\\Research\\FinalDataset\\FinalData\\unique_2VGG_FINAL\\\\midi\\00066.MID\n",
      "E:\\uniSlides\\CS\\Research\\FinalDataset\\FinalData\\unique_2VGG_FINAL\\\\midi\\00067.MID\n",
      "E:\\uniSlides\\CS\\Research\\FinalDataset\\FinalData\\unique_2VGG_FINAL\\\\midi\\00074.MID\n",
      "E:\\uniSlides\\CS\\Research\\FinalDataset\\FinalData\\unique_2VGG_FINAL\\\\midi\\00075.MID\n",
      "E:\\uniSlides\\CS\\Research\\FinalDataset\\FinalData\\unique_2VGG_FINAL\\\\midi\\00076.MID\n",
      "E:\\uniSlides\\CS\\Research\\FinalDataset\\FinalData\\unique_2VGG_FINAL\\\\midi\\00077.MID\n",
      "E:\\uniSlides\\CS\\Research\\FinalDataset\\FinalData\\unique_2VGG_FINAL\\\\midi\\00078.MID\n",
      "E:\\uniSlides\\CS\\Research\\FinalDataset\\FinalData\\unique_2VGG_FINAL\\\\midi\\00079.MID\n",
      "E:\\uniSlides\\CS\\Research\\FinalDataset\\FinalData\\unique_2VGG_FINAL\\\\midi\\00082.MID\n",
      "E:\\uniSlides\\CS\\Research\\FinalDataset\\FinalData\\unique_2VGG_FINAL\\\\midi\\00083.MID\n",
      "E:\\uniSlides\\CS\\Research\\FinalDataset\\FinalData\\unique_2VGG_FINAL\\\\midi\\00084.MID\n",
      "E:\\uniSlides\\CS\\Research\\FinalDataset\\FinalData\\unique_2VGG_FINAL\\\\midi\\00085.MID\n",
      "E:\\uniSlides\\CS\\Research\\FinalDataset\\FinalData\\unique_2VGG_FINAL\\\\midi\\00086.MID\n",
      "E:\\uniSlides\\CS\\Research\\FinalDataset\\FinalData\\unique_2VGG_FINAL\\\\midi\\00089.MID\n",
      "E:\\uniSlides\\CS\\Research\\FinalDataset\\FinalData\\unique_2VGG_FINAL\\\\midi\\00092.MID\n",
      "E:\\uniSlides\\CS\\Research\\FinalDataset\\FinalData\\unique_2VGG_FINAL\\\\midi\\00094.MID\n",
      "E:\\uniSlides\\CS\\Research\\FinalDataset\\FinalData\\unique_2VGG_FINAL\\\\midi\\id(03D155E7-6199-4F24-8531-A6A21FA25359).MID\n",
      "E:\\uniSlides\\CS\\Research\\FinalDataset\\FinalData\\unique_2VGG_FINAL\\\\midi\\id(049D17D7-EBF5-4970-910E-EFD887939C9C).MID\n",
      "E:\\uniSlides\\CS\\Research\\FinalDataset\\FinalData\\unique_2VGG_FINAL\\\\midi\\id(2550818C-F229-4A47-A15F-F37C15849B82).MID\n",
      "E:\\uniSlides\\CS\\Research\\FinalDataset\\FinalData\\unique_2VGG_FINAL\\\\midi\\id(2ABD7235-B12B-4662-8FCC-316AD10980AE).MID\n",
      "E:\\uniSlides\\CS\\Research\\FinalDataset\\FinalData\\unique_2VGG_FINAL\\\\midi\\id(2B04D7D5-ED5F-43D8-B2EF-83BD26289973).MID\n",
      "E:\\uniSlides\\CS\\Research\\FinalDataset\\FinalData\\unique_2VGG_FINAL\\\\midi\\id(36FA8856-C7B6-4602-BE5B-25B306DD3EC2).MID\n",
      "E:\\uniSlides\\CS\\Research\\FinalDataset\\FinalData\\unique_2VGG_FINAL\\\\midi\\id(3DE7049C-2D8B-4881-8E01-E8BBD1194D48).MID\n",
      "E:\\uniSlides\\CS\\Research\\FinalDataset\\FinalData\\unique_2VGG_FINAL\\\\midi\\id(3FAE5341-678F-4C52-A6B1-8DDD3264BA60).MID\n",
      "E:\\uniSlides\\CS\\Research\\FinalDataset\\FinalData\\unique_2VGG_FINAL\\\\midi\\id(4715390B-3921-404B-B3B7-023145F18B6B).MID\n",
      "E:\\uniSlides\\CS\\Research\\FinalDataset\\FinalData\\unique_2VGG_FINAL\\\\midi\\id(52C8D6E8-9E09-45E4-A3B3-DCBDD2B55322).MID\n",
      "E:\\uniSlides\\CS\\Research\\FinalDataset\\FinalData\\unique_2VGG_FINAL\\\\midi\\id(56630934-7D38-4BB2-92AB-14207EB13218).MID\n",
      "E:\\uniSlides\\CS\\Research\\FinalDataset\\FinalData\\unique_2VGG_FINAL\\\\midi\\id(5A30CCE3-83EE-433D-989F-BF01240D91EF).MID\n",
      "E:\\uniSlides\\CS\\Research\\FinalDataset\\FinalData\\unique_2VGG_FINAL\\\\midi\\id(62561F70-3C76-461B-95B0-D9F9A1C6336F).MID\n",
      "E:\\uniSlides\\CS\\Research\\FinalDataset\\FinalData\\unique_2VGG_FINAL\\\\midi\\id(854FE45A-8267-48A8-8DB4-678967169A73).MID\n",
      "E:\\uniSlides\\CS\\Research\\FinalDataset\\FinalData\\unique_2VGG_FINAL\\\\midi\\id(8A51ED41-16BF-4D10-8302-259E694E1E2A).MID\n",
      "E:\\uniSlides\\CS\\Research\\FinalDataset\\FinalData\\unique_2VGG_FINAL\\\\midi\\id(9604342C-6FB6-4C2E-AE24-C3344958CD26).MID\n",
      "E:\\uniSlides\\CS\\Research\\FinalDataset\\FinalData\\unique_2VGG_FINAL\\\\midi\\id(9A330A2A-A40B-4BCB-A95A-61E9388C53AC).MID\n",
      "E:\\uniSlides\\CS\\Research\\FinalDataset\\FinalData\\unique_2VGG_FINAL\\\\midi\\id(AB7B9096-92C1-4392-821C-F7DDB4375B5C).MID\n",
      "E:\\uniSlides\\CS\\Research\\FinalDataset\\FinalData\\unique_2VGG_FINAL\\\\midi\\id(FF906F27-24A3-4352-BBD8-CF79F722A9CD).MID\n",
      "Finishes writing midi data. 60 songs written.\n"
     ]
    }
   ],
   "source": [
    "createDatafile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_9HC_NSHDMJK"
   },
   "source": [
    "Load Saved file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "mwDzeohbDLni"
   },
   "outputs": [],
   "source": [
    "content = load_file(data_dir + \"midiData.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "psREIoqyC5JO"
   },
   "source": [
    "Create a Dictionary with midi data, obtain vocabulary and get the max length of a midi sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G8-T6VyJDBrO",
    "outputId": "cf1b0f27-15dc-452e-facc-bfca3168fffb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary length = 340\n",
      "Maximum length sequence = 114\n"
     ]
    }
   ],
   "source": [
    "train_midi, vocabulary, maxLength = dict_vocab_maxLength(content)\n",
    "#print vocabulary length\n",
    "vocabSize = len(vocabulary) + 1\n",
    "print(\"Vocabulary length = \" + str(vocabSize))\n",
    "#print max length of sequence\n",
    "print(\"Maximum length sequence = \" + str(maxLength))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iBEd7JyIEpfp"
   },
   "source": [
    "Tokenize vocabulary and save tokenizer pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens: 339\n"
     ]
    }
   ],
   "source": [
    "tokenizer = tokenize(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gYbTWJgKErhS",
    "outputId": "f0bc0892-f383-43f0-a3dd-23ab71449101"
   },
   "outputs": [],
   "source": [
    "dump(tokenizer, open(data_dir + 'tokenizer.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BZeWPmLg8uyc"
   },
   "source": [
    "## **Image Preprocessing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n2XMCa22EDEb"
   },
   "source": [
    "### **Function Definitions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P2JyaE2b8-CI"
   },
   "source": [
    "Function to extract image features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "3A-hcdus8zj5"
   },
   "outputs": [],
   "source": [
    "def extract_Image_features(directory, modelName = current_ImgModel):\n",
    "  #check for the model needed and initialize the model and image size\n",
    "  if modelName == label_VGG16:\n",
    "    model = VGG16()\n",
    "    imgSize = (224, 224)\n",
    "  else:\n",
    "    model = InceptionV3(weights='imagenet')\n",
    "    imgSize = (299, 299)\n",
    "\n",
    "  #remove the last layer of the model to obtain the features\n",
    "  #VGG16 has 4096 and InceptionV3 has 2048\n",
    "  model = Model(inputs=model.inputs, outputs=model.layers[-2].output)\n",
    "\n",
    "  #print model summary\n",
    "  print(model.summary())\n",
    "\n",
    "  #intialize dictionary to extract features\n",
    "  features = dict()\n",
    "\n",
    "  #loop over each image in directory\n",
    "  for imgName in listdir(directory):\n",
    "    #get image path\n",
    "    path = directory + '/' + imgName\n",
    "    #load image and resize\n",
    "    image = load_img(path, target_size=imgSize)\n",
    "    #convert image to numpy array\n",
    "    image = img_to_array(image)\n",
    "    #reshape image to suit model\n",
    "    image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
    "    #preprocess image for the model\n",
    "    image = preprocess_input(image)\n",
    "    #extract features\n",
    "    feature = model.predict(image, verbose=0)\n",
    "    #get image id\n",
    "    image_id = imgName.split('.')[0]\n",
    "    #append to dictionary\n",
    "    features[image_id] = feature\n",
    "\n",
    "    #print image name\n",
    "    print(\"Features extracted for \" + imgName)\n",
    "  \n",
    "  return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ByIbA3RVtTw7"
   },
   "source": [
    "Function to load photo features from pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "4cwCpsK9tTG5"
   },
   "outputs": [],
   "source": [
    "def load_featuresPickle(path):\n",
    "  #load all features\n",
    "  features = load(open(path, 'rb'))\n",
    "  return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0pG6X7P7EUEz"
   },
   "source": [
    "### Image Preprocessing Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8Mz1iWeLAbFM",
    "outputId": "6e12aade-4b1e-4860-8706-47c765293c49"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_10 (InputLayer)       [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " fc1 (Dense)                 (None, 4096)              102764544 \n",
      "                                                                 \n",
      " fc2 (Dense)                 (None, 4096)              16781312  \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 134,260,544\n",
      "Trainable params: 134,260,544\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Features extracted for 00008A.png\n",
      "Features extracted for 00008A1.png\n",
      "Features extracted for 00008A2.png\n",
      "Features extracted for 00008A3.png\n",
      "Features extracted for 00008A4.png\n",
      "Features extracted for 00009B.png\n",
      "Features extracted for 00009B1.png\n",
      "Features extracted for 00009B2.png\n",
      "Features extracted for 00009B3.png\n",
      "Features extracted for 00009B4.png\n",
      "Features extracted for 00016B.png\n",
      "Features extracted for 00016B1.png\n",
      "Features extracted for 00016B2.png\n",
      "Features extracted for 00016B3.png\n",
      "Features extracted for 00016B4.png\n",
      "Features extracted for 00018C.png\n",
      "Features extracted for 00018C1.png\n",
      "Features extracted for 00018C2.png\n",
      "Features extracted for 00018C3.png\n",
      "Features extracted for 00018C4.png\n",
      "Features extracted for 00021C.png\n",
      "Features extracted for 00021C1.png\n",
      "Features extracted for 00021C2.png\n",
      "Features extracted for 00021C3.png\n",
      "Features extracted for 00021C4.png\n",
      "Features extracted for 00024C.png\n",
      "Features extracted for 00024C1.png\n",
      "Features extracted for 00024C2.png\n",
      "Features extracted for 00024C3.png\n",
      "Features extracted for 00024C4.png\n",
      "Features extracted for 00027B.png\n",
      "Features extracted for 00027B1.png\n",
      "Features extracted for 00027B2.png\n",
      "Features extracted for 00027B3.png\n",
      "Features extracted for 00027B4.png\n",
      "Features extracted for 00028B.png\n",
      "Features extracted for 00028B1.png\n",
      "Features extracted for 00028B2.png\n",
      "Features extracted for 00028B3.png\n",
      "Features extracted for 00028B4.png\n",
      "Features extracted for 00029C.png\n",
      "Features extracted for 00029C1.png\n",
      "Features extracted for 00029C2.png\n",
      "Features extracted for 00029C3.png\n",
      "Features extracted for 00029C4.png\n",
      "Features extracted for 00030B.png\n",
      "Features extracted for 00030B1.png\n",
      "Features extracted for 00030B2.png\n",
      "Features extracted for 00030B3.png\n",
      "Features extracted for 00030B4.png\n",
      "Features extracted for 00033C.png\n",
      "Features extracted for 00033C1.png\n",
      "Features extracted for 00033C2.png\n",
      "Features extracted for 00033C3.png\n",
      "Features extracted for 00033C4.png\n",
      "Features extracted for 00034A.png\n",
      "Features extracted for 00034A1.png\n",
      "Features extracted for 00034A2.png\n",
      "Features extracted for 00034A3.png\n",
      "Features extracted for 00034A4.png\n",
      "Features extracted for 00036A.png\n",
      "Features extracted for 00036A1.png\n",
      "Features extracted for 00036A2.png\n",
      "Features extracted for 00036A3.png\n",
      "Features extracted for 00036A4.png\n",
      "Features extracted for 00037D.png\n",
      "Features extracted for 00037D1.png\n",
      "Features extracted for 00037D2.png\n",
      "Features extracted for 00037D3.png\n",
      "Features extracted for 00037D4.png\n",
      "Features extracted for 00038B.png\n",
      "Features extracted for 00038B1.png\n",
      "Features extracted for 00038B2.png\n",
      "Features extracted for 00038B3.png\n",
      "Features extracted for 00038B4.png\n",
      "Features extracted for 00040A.png\n",
      "Features extracted for 00040A1.png\n",
      "Features extracted for 00040A2.png\n",
      "Features extracted for 00040A3.png\n",
      "Features extracted for 00040A4.png\n",
      "Features extracted for 00051B.png\n",
      "Features extracted for 00051B1.png\n",
      "Features extracted for 00051B2.png\n",
      "Features extracted for 00051B3.png\n",
      "Features extracted for 00051B4.png\n",
      "Features extracted for 00053C.png\n",
      "Features extracted for 00053C1.png\n",
      "Features extracted for 00053C2.png\n",
      "Features extracted for 00053C3.png\n",
      "Features extracted for 00053C4.png\n",
      "Features extracted for 00054F.png\n",
      "Features extracted for 00054F1.png\n",
      "Features extracted for 00054F2.png\n",
      "Features extracted for 00054F3.png\n",
      "Features extracted for 00054F4.png\n",
      "Features extracted for 00055F.png\n",
      "Features extracted for 00055F1.png\n",
      "Features extracted for 00055F2.png\n",
      "Features extracted for 00055F3.png\n",
      "Features extracted for 00055F4.png\n",
      "Features extracted for 00056B.png\n",
      "Features extracted for 00056B1.png\n",
      "Features extracted for 00056B2.png\n",
      "Features extracted for 00056B3.png\n",
      "Features extracted for 00056B4.png\n",
      "Features extracted for 00057A.png\n",
      "Features extracted for 00057A1.png\n",
      "Features extracted for 00057A2.png\n",
      "Features extracted for 00057A3.png\n",
      "Features extracted for 00057A4.png\n",
      "Features extracted for 00059A.png\n",
      "Features extracted for 00059A1.png\n",
      "Features extracted for 00059A2.png\n",
      "Features extracted for 00059A3.png\n",
      "Features extracted for 00059A4.png\n",
      "Features extracted for 00063G.png\n",
      "Features extracted for 00063G1.png\n",
      "Features extracted for 00063G2.png\n",
      "Features extracted for 00063G3.png\n",
      "Features extracted for 00063G4.png\n",
      "Features extracted for 00065E.png\n",
      "Features extracted for 00065E1.png\n",
      "Features extracted for 00065E2.png\n",
      "Features extracted for 00065E3.png\n",
      "Features extracted for 00065E4.png\n",
      "Features extracted for 00066E.png\n",
      "Features extracted for 00066E1.png\n",
      "Features extracted for 00066E2.png\n",
      "Features extracted for 00066E3.png\n",
      "Features extracted for 00066E4.png\n",
      "Features extracted for 00067A.png\n",
      "Features extracted for 00067A1.png\n",
      "Features extracted for 00067A2.png\n",
      "Features extracted for 00067A3.png\n",
      "Features extracted for 00067A4.png\n",
      "Features extracted for 00074B.png\n",
      "Features extracted for 00074B1.png\n",
      "Features extracted for 00074B2.png\n",
      "Features extracted for 00074B3.png\n",
      "Features extracted for 00074B4.png\n",
      "Features extracted for 00075C.png\n",
      "Features extracted for 00075C1.png\n",
      "Features extracted for 00075C2.png\n",
      "Features extracted for 00075C3.png\n",
      "Features extracted for 00075C4.png\n",
      "Features extracted for 00076G.png\n",
      "Features extracted for 00076G1.png\n",
      "Features extracted for 00076G2.png\n",
      "Features extracted for 00076G3.png\n",
      "Features extracted for 00076G4.png\n",
      "Features extracted for 00077D.png\n",
      "Features extracted for 00077D1.png\n",
      "Features extracted for 00077D2.png\n",
      "Features extracted for 00077D3.png\n",
      "Features extracted for 00077D4.png\n",
      "Features extracted for 00078B.png\n",
      "Features extracted for 00078B1.png\n",
      "Features extracted for 00078B2.png\n",
      "Features extracted for 00078B3.png\n",
      "Features extracted for 00078B4.png\n",
      "Features extracted for 00079D.png\n",
      "Features extracted for 00079D1.png\n",
      "Features extracted for 00079D2.png\n",
      "Features extracted for 00079D3.png\n",
      "Features extracted for 00079D4.png\n",
      "Features extracted for 00082E.png\n",
      "Features extracted for 00082E1.png\n",
      "Features extracted for 00082E2.png\n",
      "Features extracted for 00082E3.png\n",
      "Features extracted for 00082E4.png\n",
      "Features extracted for 00083B.png\n",
      "Features extracted for 00083B1.png\n",
      "Features extracted for 00083B2.png\n",
      "Features extracted for 00083B3.png\n",
      "Features extracted for 00083B4.png\n",
      "Features extracted for 00084B.png\n",
      "Features extracted for 00084B1.png\n",
      "Features extracted for 00084B2.png\n",
      "Features extracted for 00084B3.png\n",
      "Features extracted for 00084B4.png\n",
      "Features extracted for 00085C.png\n",
      "Features extracted for 00085C1.png\n",
      "Features extracted for 00085C2.png\n",
      "Features extracted for 00085C3.png\n",
      "Features extracted for 00085C4.png\n",
      "Features extracted for 00086C.png\n",
      "Features extracted for 00086C1.png\n",
      "Features extracted for 00086C2.png\n",
      "Features extracted for 00086C3.png\n",
      "Features extracted for 00086C4.png\n",
      "Features extracted for 00089E.png\n",
      "Features extracted for 00089E1.png\n",
      "Features extracted for 00089E2.png\n",
      "Features extracted for 00089E3.png\n",
      "Features extracted for 00089E4.png\n",
      "Features extracted for 00092E.png\n",
      "Features extracted for 00092E1.png\n",
      "Features extracted for 00092E2.png\n",
      "Features extracted for 00092E3.png\n",
      "Features extracted for 00092E4.png\n",
      "Features extracted for 00094A.png\n",
      "Features extracted for 00094A1.png\n",
      "Features extracted for 00094A2.png\n",
      "Features extracted for 00094A3.png\n",
      "Features extracted for 00094A4.png\n",
      "Features extracted for id(03D155E7-6199-4F24-8531-A6A21FA25359)_image.jpg\n",
      "Features extracted for id(03D155E7-6199-4F24-8531-A6A21FA25359)_image1.png\n",
      "Features extracted for id(03D155E7-6199-4F24-8531-A6A21FA25359)_image2.png\n",
      "Features extracted for id(03D155E7-6199-4F24-8531-A6A21FA25359)_image3.png\n",
      "Features extracted for id(03D155E7-6199-4F24-8531-A6A21FA25359)_image4.png\n",
      "Features extracted for id(049D17D7-EBF5-4970-910E-EFD887939C9C)_image.jpg\n",
      "Features extracted for id(049D17D7-EBF5-4970-910E-EFD887939C9C)_image1.png\n",
      "Features extracted for id(049D17D7-EBF5-4970-910E-EFD887939C9C)_image2.png\n",
      "Features extracted for id(049D17D7-EBF5-4970-910E-EFD887939C9C)_image3.png\n",
      "Features extracted for id(049D17D7-EBF5-4970-910E-EFD887939C9C)_image4.png\n",
      "Features extracted for id(2550818C-F229-4A47-A15F-F37C15849B82)_image.jpg\n",
      "Features extracted for id(2550818C-F229-4A47-A15F-F37C15849B82)_image1.png\n",
      "Features extracted for id(2550818C-F229-4A47-A15F-F37C15849B82)_image2.png\n",
      "Features extracted for id(2550818C-F229-4A47-A15F-F37C15849B82)_image3.png\n",
      "Features extracted for id(2550818C-F229-4A47-A15F-F37C15849B82)_image4.png\n",
      "Features extracted for id(2ABD7235-B12B-4662-8FCC-316AD10980AE)_image1.png\n",
      "Features extracted for id(2ABD7235-B12B-4662-8FCC-316AD10980AE)_image11.png\n",
      "Features extracted for id(2ABD7235-B12B-4662-8FCC-316AD10980AE)_image12.png\n",
      "Features extracted for id(2ABD7235-B12B-4662-8FCC-316AD10980AE)_image13.png\n",
      "Features extracted for id(2ABD7235-B12B-4662-8FCC-316AD10980AE)_image14.png\n",
      "Features extracted for id(2B04D7D5-ED5F-43D8-B2EF-83BD26289973)_image.jpg\n",
      "Features extracted for id(2B04D7D5-ED5F-43D8-B2EF-83BD26289973)_image1.png\n",
      "Features extracted for id(2B04D7D5-ED5F-43D8-B2EF-83BD26289973)_image2.png\n",
      "Features extracted for id(2B04D7D5-ED5F-43D8-B2EF-83BD26289973)_image3.png\n",
      "Features extracted for id(2B04D7D5-ED5F-43D8-B2EF-83BD26289973)_image4.png\n",
      "Features extracted for id(36FA8856-C7B6-4602-BE5B-25B306DD3EC2)_image1.png\n",
      "Features extracted for id(36FA8856-C7B6-4602-BE5B-25B306DD3EC2)_image11.png\n",
      "Features extracted for id(36FA8856-C7B6-4602-BE5B-25B306DD3EC2)_image12.png\n",
      "Features extracted for id(36FA8856-C7B6-4602-BE5B-25B306DD3EC2)_image13.png\n",
      "Features extracted for id(36FA8856-C7B6-4602-BE5B-25B306DD3EC2)_image14.png\n",
      "Features extracted for id(3DE7049C-2D8B-4881-8E01-E8BBD1194D48)_image.jpg\n",
      "Features extracted for id(3DE7049C-2D8B-4881-8E01-E8BBD1194D48)_image1.png\n",
      "Features extracted for id(3DE7049C-2D8B-4881-8E01-E8BBD1194D48)_image2.png\n",
      "Features extracted for id(3DE7049C-2D8B-4881-8E01-E8BBD1194D48)_image3.png\n",
      "Features extracted for id(3DE7049C-2D8B-4881-8E01-E8BBD1194D48)_image4.png\n",
      "Features extracted for id(3FAE5341-678F-4C52-A6B1-8DDD3264BA60)_image.jpg\n",
      "Features extracted for id(3FAE5341-678F-4C52-A6B1-8DDD3264BA60)_image1.png\n",
      "Features extracted for id(3FAE5341-678F-4C52-A6B1-8DDD3264BA60)_image2.png\n",
      "Features extracted for id(3FAE5341-678F-4C52-A6B1-8DDD3264BA60)_image3.png\n",
      "Features extracted for id(3FAE5341-678F-4C52-A6B1-8DDD3264BA60)_image4.png\n",
      "Features extracted for id(4715390B-3921-404B-B3B7-023145F18B6B)_image.jpg\n",
      "Features extracted for id(4715390B-3921-404B-B3B7-023145F18B6B)_image1.png\n",
      "Features extracted for id(4715390B-3921-404B-B3B7-023145F18B6B)_image2.png\n",
      "Features extracted for id(4715390B-3921-404B-B3B7-023145F18B6B)_image3.png\n",
      "Features extracted for id(4715390B-3921-404B-B3B7-023145F18B6B)_image4.png\n",
      "Features extracted for id(52C8D6E8-9E09-45E4-A3B3-DCBDD2B55322)_image.jpg\n",
      "Features extracted for id(52C8D6E8-9E09-45E4-A3B3-DCBDD2B55322)_image1.png\n",
      "Features extracted for id(52C8D6E8-9E09-45E4-A3B3-DCBDD2B55322)_image2.png\n",
      "Features extracted for id(52C8D6E8-9E09-45E4-A3B3-DCBDD2B55322)_image3.png\n",
      "Features extracted for id(52C8D6E8-9E09-45E4-A3B3-DCBDD2B55322)_image4.png\n",
      "Features extracted for id(56630934-7D38-4BB2-92AB-14207EB13218)_image1.png\n",
      "Features extracted for id(56630934-7D38-4BB2-92AB-14207EB13218)_image11.png\n",
      "Features extracted for id(56630934-7D38-4BB2-92AB-14207EB13218)_image12.png\n",
      "Features extracted for id(56630934-7D38-4BB2-92AB-14207EB13218)_image13.png\n",
      "Features extracted for id(56630934-7D38-4BB2-92AB-14207EB13218)_image14.png\n",
      "Features extracted for id(5A30CCE3-83EE-433D-989F-BF01240D91EF)_image.jpg\n",
      "Features extracted for id(5A30CCE3-83EE-433D-989F-BF01240D91EF)_image1.png\n",
      "Features extracted for id(5A30CCE3-83EE-433D-989F-BF01240D91EF)_image2.png\n",
      "Features extracted for id(5A30CCE3-83EE-433D-989F-BF01240D91EF)_image3.png\n",
      "Features extracted for id(5A30CCE3-83EE-433D-989F-BF01240D91EF)_image4.png\n",
      "Features extracted for id(62561F70-3C76-461B-95B0-D9F9A1C6336F)_image.jpg\n",
      "Features extracted for id(62561F70-3C76-461B-95B0-D9F9A1C6336F)_image1.png\n",
      "Features extracted for id(62561F70-3C76-461B-95B0-D9F9A1C6336F)_image2.png\n",
      "Features extracted for id(62561F70-3C76-461B-95B0-D9F9A1C6336F)_image3.png\n",
      "Features extracted for id(62561F70-3C76-461B-95B0-D9F9A1C6336F)_image4.png\n",
      "Features extracted for id(854FE45A-8267-48A8-8DB4-678967169A73)_image.jpg\n",
      "Features extracted for id(854FE45A-8267-48A8-8DB4-678967169A73)_image1.png\n",
      "Features extracted for id(854FE45A-8267-48A8-8DB4-678967169A73)_image2.png\n",
      "Features extracted for id(854FE45A-8267-48A8-8DB4-678967169A73)_image3.png\n",
      "Features extracted for id(854FE45A-8267-48A8-8DB4-678967169A73)_image4.png\n",
      "Features extracted for id(8A51ED41-16BF-4D10-8302-259E694E1E2A)_image.jpg\n",
      "Features extracted for id(8A51ED41-16BF-4D10-8302-259E694E1E2A)_image1.png\n",
      "Features extracted for id(8A51ED41-16BF-4D10-8302-259E694E1E2A)_image2.png\n",
      "Features extracted for id(8A51ED41-16BF-4D10-8302-259E694E1E2A)_image3.png\n",
      "Features extracted for id(8A51ED41-16BF-4D10-8302-259E694E1E2A)_image4.png\n",
      "Features extracted for id(9604342C-6FB6-4C2E-AE24-C3344958CD26)_image.jpg\n",
      "Features extracted for id(9604342C-6FB6-4C2E-AE24-C3344958CD26)_image1.png\n",
      "Features extracted for id(9604342C-6FB6-4C2E-AE24-C3344958CD26)_image2.png\n",
      "Features extracted for id(9604342C-6FB6-4C2E-AE24-C3344958CD26)_image3.png\n",
      "Features extracted for id(9604342C-6FB6-4C2E-AE24-C3344958CD26)_image4.png\n",
      "Features extracted for id(9A330A2A-A40B-4BCB-A95A-61E9388C53AC)_image.jpg\n",
      "Features extracted for id(9A330A2A-A40B-4BCB-A95A-61E9388C53AC)_image1.png\n",
      "Features extracted for id(9A330A2A-A40B-4BCB-A95A-61E9388C53AC)_image2.png\n",
      "Features extracted for id(9A330A2A-A40B-4BCB-A95A-61E9388C53AC)_image3.png\n",
      "Features extracted for id(9A330A2A-A40B-4BCB-A95A-61E9388C53AC)_image4.png\n",
      "Features extracted for id(AB7B9096-92C1-4392-821C-F7DDB4375B5C)_image.jpg\n",
      "Features extracted for id(AB7B9096-92C1-4392-821C-F7DDB4375B5C)_image1.png\n",
      "Features extracted for id(AB7B9096-92C1-4392-821C-F7DDB4375B5C)_image2.png\n",
      "Features extracted for id(AB7B9096-92C1-4392-821C-F7DDB4375B5C)_image3.png\n",
      "Features extracted for id(AB7B9096-92C1-4392-821C-F7DDB4375B5C)_image4.png\n",
      "Features extracted for id(FF906F27-24A3-4352-BBD8-CF79F722A9CD)_image.jpg\n",
      "Features extracted for id(FF906F27-24A3-4352-BBD8-CF79F722A9CD)_image1.png\n",
      "Features extracted for id(FF906F27-24A3-4352-BBD8-CF79F722A9CD)_image2.png\n",
      "Features extracted for id(FF906F27-24A3-4352-BBD8-CF79F722A9CD)_image3.png\n",
      "Features extracted for id(FF906F27-24A3-4352-BBD8-CF79F722A9CD)_image4.png\n"
     ]
    }
   ],
   "source": [
    "features = extract_Image_features(data_dir + 'images')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7EgefBoOFKTG"
   },
   "source": [
    "Dump feature to pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FVF6SxL8FIty",
    "outputId": "86ed6683-613f-496e-b056-db5eafbd7895"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted features : 300\n"
     ]
    }
   ],
   "source": [
    "#print length of features\n",
    "print(\"Extracted features : %d\" % len(features))\n",
    "# save to pickle file\n",
    "dump(features, open(data_dir + 'features.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cl3Xy0xWFm7E"
   },
   "source": [
    "# **Model Creation, Training and related Functions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ECQrnArIFm_f"
   },
   "source": [
    "## **Function Definitions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KQfG_4ZwIgYU"
   },
   "source": [
    "Function to create a deep learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "HWgf5xuuGSCr"
   },
   "outputs": [],
   "source": [
    "def create_Model(vocabSize, maxLength):\n",
    "  #image feature extractor model\n",
    "  if current_ImgModel == label_VGG16:\n",
    "    inputs1 = Input(shape = (4096, ))\n",
    "  elif current_ImgModel == label_InceptionV3:\n",
    "    inputs1 = Input(shape = (2048, ))\n",
    "\n",
    "  fe1 = Dropout(0.5)(inputs1)\n",
    "  fe2 = Dense(256, activation='relu')(fe1)\n",
    "\n",
    "  #midi sequence model\n",
    "  inputs2 = Input(shape=(maxLength,))\n",
    "  #Embedding layer\n",
    "  se1 = Embedding(vocabSize, 256, mask_zero=True)(inputs2)\n",
    "  se2 = Dropout(0.2)(se1)\n",
    "  se3 = LSTM(128, return_sequences=True)(se2)\n",
    "  se4 = Dropout(0.2)(se3)\n",
    "  se5 = LSTM(256)(se4)\n",
    "\n",
    "  #decoder model\n",
    "  decoder1 = add([fe2, se5])\n",
    "  decoder2 = Dense(256, activation='relu')(decoder1)\n",
    "  outputs = Dense(vocabSize, activation='softmax')(decoder2)\n",
    "\n",
    "  #Merger model\n",
    "  model = Model(inputs=[inputs1, inputs2], outputs=outputs)\n",
    "  #compile model\n",
    "  model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "  #print model summary\n",
    "  print(\"Model Summary\")\n",
    "  model.summary()\n",
    "  plot_model(model, to_file=data_dir + 'model.png', show_shapes=True)\n",
    "  return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9dFQ3iI_Ij9D"
   },
   "source": [
    "Function to generate input sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "ND_o1hzhIm8D"
   },
   "outputs": [],
   "source": [
    "def create_sequences(tokenizer, max_length, midi_list, photo, vocab_size):\n",
    "  #initialize input lists\n",
    "  X1, X2, y = list(), list(), list()\n",
    "  #loop through each midi song for the image\n",
    "  for midi in midi_list:\n",
    "    #encode the midi sequence\n",
    "    seq = tokenizer.texts_to_sequences([midi])[0]\n",
    "    #generate multiple X,y pairs from one midi file\n",
    "    for i in range(1, len(seq)):\n",
    "      #generate input and output pair\n",
    "      in_seq, out_seq = seq[:i], seq[i]\n",
    "      #pad input sequence\n",
    "      in_seq = pad_sequences([in_seq], maxlen=max_length)[0]\n",
    "      #encode output Sequence\n",
    "      out_seq = to_categorical([out_seq], num_classes=vocab_size)[0]\n",
    "      #append to input lists\n",
    "      X1.append(photo)\n",
    "      X2.append(in_seq)\n",
    "      y.append(out_seq)\n",
    "  \n",
    "  return array(X1), array(X2), array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "59yiMayAIkDr"
   },
   "source": [
    "Function to generate data for progressive loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "iJkN-DrDP6XM"
   },
   "outputs": [],
   "source": [
    "def data_generator(midiData, photos, tokenizer, max_length, vocab_size):\n",
    "  #loop forever\n",
    "  while True:\n",
    "    for key, midi_list in midiData.items():\n",
    "      #get photo features\n",
    "      photo = photos[key][0]\n",
    "      in_img, in_seq, out_word = create_sequences(tokenizer, max_length, midi_list, photo, vocab_size)\n",
    "      yield [in_img, in_seq], out_word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k2dCvTXvQfiS"
   },
   "source": [
    "Function to map output integer to midi vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "b4Y2mDvsQnYL"
   },
   "outputs": [],
   "source": [
    "def get_midiString_for_Integer(integer, tokenizer):\n",
    "  #loop through tokenizer to find a match\n",
    "  for midiString, index in tokenizer.word_index.items():\n",
    "    if index == integer:\n",
    "      return midiString\n",
    "  return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ihlP02MoR2SB"
   },
   "source": [
    "Function to generate midi string for image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "e6dbrDabR9pC"
   },
   "outputs": [],
   "source": [
    "def generate_midiSequence(model, tokenizer, photo, maxLength):\n",
    "  #create initial token\n",
    "  midiSequence = '<start>' #string with midi events including <start> and <end> tokens\n",
    "  prediction_list = [] #list with midi events without <start> and <end> tokens\n",
    "\n",
    "  #iterate over max length of a sequence\n",
    "  for i in range(maxLength):\n",
    "    #encode sequence\n",
    "    sequence =  tokenizer.texts_to_sequences([midiSequence])[0]\n",
    "    #pad sequence\n",
    "    sequence = pad_sequences([sequence], maxlen=maxLength)\n",
    "    #predict next midi event string\n",
    "    yhat = model.predict([photo,sequence], verbose=0)\n",
    "    #print(yhat)\n",
    "    #obtain event with highest probability\n",
    "    #import numpy as np\n",
    "    #yhat2 = np.argsort(np.max(yhat, axis=0))[-2]\n",
    "    yhat = argmax(yhat)\n",
    "    #map integer to midi string\n",
    "    midiString = get_midiString_for_Integer(yhat, tokenizer)\n",
    "    #stop if cannot find\n",
    "    if midiString is None:\n",
    "      break\n",
    "    #append midiString to sequence\n",
    "    if not midiString == '<start>':\n",
    "        midiSequence += ' ' + midiString\n",
    "    #stop if end of midi\n",
    "    if midiString == '<end>':\n",
    "      break\n",
    "    #append midi event string to prediction list\n",
    "    if not midiString == '<start>':\n",
    "        prediction_list.append(midiString)\n",
    "  \n",
    "  return midiSequence, prediction_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0ojfqhU4UXOb"
   },
   "source": [
    "Function to create a midi from prediction list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "RzEdWOyeUabd"
   },
   "outputs": [],
   "source": [
    "def create_midi(prediction_output, midiName):\n",
    "  #initiate offset to 0\n",
    "  offset = 0.0\n",
    "  #initiate midi stram\n",
    "  midi_stream = stream.Stream()\n",
    "\n",
    "  #loop over each midiString patter in prediction Output\n",
    "  for pattern in prediction_output:\n",
    "    #Seperate midiString into event and time by @ symbol\n",
    "    patternString = pattern.split('@')[0] #0 position stores midi event\n",
    "    if pattern.split('@')[1] == 'tempo':\n",
    "      #if event is a tempo, append to midiStream and continue to next iteration\n",
    "      tp0 = tempo.MetronomeMark(patternString)\n",
    "      tp0.setQuarterBPM(int(float(patternString))) \n",
    "      midi_stream.append(tp0)\n",
    "      continue\n",
    "    #check if position 1 == time to check if event is a timeSignature\n",
    "    if pattern.split('@')[1] == 'time':\n",
    "      #if event is a timeSignature, append to midiStream and continue to next iteration\n",
    "      ts0 = meter.TimeSignature(patternString)\n",
    "      midi_stream.append(ts0)\n",
    "      continue\n",
    "    #check if '.' in patterString  or it patternString is a digit to detemine if the event is a chord\n",
    "    if ('.' in patternString) or patternString.isdigit():\n",
    "        #if event is a chord, obtain notes\n",
    "        notes_in_chord = patternString.split('.')\n",
    "        notes = []\n",
    "        #loop for each note and create a notes list\n",
    "        for current_note in notes_in_chord:\n",
    "          new_note = note.Note(int(current_note))\n",
    "          new_note.storedInstrument = instrument.Piano()\n",
    "          notes.append(new_note)\n",
    "        #create a chord using notes list\n",
    "        new_chord = chord.Chord(notes)\n",
    "        #set duration of chord \n",
    "        new_chord.quarterLength = eval(pattern.split('@')[1])\n",
    "        #update offset\n",
    "        new_chord.offset = offset \n",
    "        offset += new_chord.quarterLength\n",
    "        #append chord to midi Stream\n",
    "        midi_stream.append(new_chord)\n",
    "    # pattern is a note or rest\n",
    "    else:\n",
    "      #if pattern is a rest\n",
    "      if patternString == 'r':\n",
    "        #create rest event\n",
    "        new_note = note.Rest()\n",
    "        #set duration\n",
    "        new_note.quarterLength = eval(pattern.split('@')[1])\n",
    "        #update offest\n",
    "        new_note.offset = offset \n",
    "        offset += new_note.quarterLength\n",
    "        #append to midi stream\n",
    "        midi_stream.append(new_note)\n",
    "      else:\n",
    "        #if pattern is a note\n",
    "        #create note\n",
    "        new_note = note.Note(patternString)\n",
    "        #set note duration\n",
    "        new_note.quarterLength = eval(pattern.split('@')[1])\n",
    "        #update offset\n",
    "        new_note.offset = offset \n",
    "        offset += new_note.quarterLength\n",
    "        new_note.storedInstrument = instrument.Piano()\n",
    "        midi_stream.append(new_note)\n",
    "              \n",
    "  midi_stream.makeMeasures(inPlace = True)\n",
    "\n",
    "  print('Saving Output file as midi....')\n",
    "\n",
    "  midi_stream.write('midi', fp=data_dir + midiName + '.mid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nTadoaIyXurG"
   },
   "source": [
    "Function to extract features of image to generate music"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "ann2qMWyXxyq"
   },
   "outputs": [],
   "source": [
    "def extract_featuresPredict(path, modelName = current_ImgModel):\n",
    "  #initialize model and resize image\n",
    "  if modelName == label_VGG16:\n",
    "    model = model = VGG16()\n",
    "    image = load_img(path, target_size=(224, 224))\n",
    "  elif modelName == label_InceptionV3:\n",
    "    model = InceptionV3(weights='imagenet')\n",
    "    image = load_img(filename, target_size=(299, 299))\n",
    "\n",
    "  #remove last layer of model\n",
    "  model = Model(inputs=model.inputs, outputs=model.layers[-2].output)\n",
    "  #convert image to numpy array\n",
    "  image = img_to_array(image)\n",
    "  #reshape array \n",
    "  image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
    "  #preprocess image\n",
    "  image = preprocess_input(image)\n",
    "  #obtain features\n",
    "  features = model.predict(image, verbose=0)\n",
    "\n",
    "  return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QYAJ6ECqDOqn"
   },
   "source": [
    "Model Creation and Training Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e8uw83ZmDbfq"
   },
   "source": [
    "Load training photo features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "PFQ62oANDY8t"
   },
   "outputs": [],
   "source": [
    "train_features = load_featuresPickle(data_dir + 'features.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tkoKbmZGKL38"
   },
   "source": [
    "Training midi data is already loaded in train_midi dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b2KqkQfDKTHb"
   },
   "source": [
    "Next create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YiraVB-fKRTf",
    "outputId": "ad2376c3-8835-47d9-be17-fdbb1a8ea1e1",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Summary\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 114)]        0           []                               \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, 114, 256)     87040       ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 114, 256)     0           ['embedding[0][0]']              \n",
      "                                                                                                  \n",
      " input_1 (InputLayer)           [(None, 4096)]       0           []                               \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    (None, 114, 128)     197120      ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 4096)         0           ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 114, 128)     0           ['lstm[0][0]']                   \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 256)          1048832     ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)                  (None, 256)          394240      ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 256)          0           ['dense[0][0]',                  \n",
      "                                                                  'lstm_1[0][0]']                 \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 256)          65792       ['add[0][0]']                    \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 340)          87380       ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,880,404\n",
      "Trainable params: 1,880,404\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#create model\n",
    "model = create_Model(vocabSize= vocabSize, maxLength=maxLength)\n",
    "#initialize epochs\n",
    "epochs = 250\n",
    "#initials steps to generate data\n",
    "steps = len(train_midi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ijw1BzBhLb3s"
   },
   "source": [
    "Define path to save best model and initialize Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save weights\n",
    "filepath = data_dir + 'training_2/cp.ckpt'\n",
    "checkpoint_dir = os.path.dirname(filepath)\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_weights_only=True, save_best_only=True, mode='min')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QyvsLB1_Ll04"
   },
   "source": [
    "Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mBXKquRPLlF7",
    "outputId": "05493e8c-d230-416f-c9e6-33d1ef59ab6d",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch No : 1\n",
      "300/300 [==============================] - ETA: 0s - loss: 5.0958\n",
      "Epoch 1: loss improved from inf to 5.09580, saving model to E:\\uniSlides\\CS\\Research\\FinalDataset\\FinalData\\unique_2VGG_FINAL\\\\training_2\\cp.ckpt\n",
      "300/300 [==============================] - 566s 2s/step - loss: 5.0958\n",
      "Epoch No : 2\n",
      "300/300 [==============================] - ETA: 0s - loss: 4.6014\n",
      "Epoch 1: loss improved from 5.09580 to 4.60135, saving model to E:\\uniSlides\\CS\\Research\\FinalDataset\\FinalData\\unique_2VGG_FINAL\\\\training_2\\cp.ckpt\n",
      "300/300 [==============================] - 551s 2s/step - loss: 4.6014\n",
      "Epoch No : 3\n",
      "300/300 [==============================] - ETA: 0s - loss: 4.3432\n",
      "Epoch 1: loss improved from 4.60135 to 4.34320, saving model to E:\\uniSlides\\CS\\Research\\FinalDataset\\FinalData\\unique_2VGG_FINAL\\\\training_2\\cp.ckpt\n",
      "300/300 [==============================] - 548s 2s/step - loss: 4.3432\n",
      "Epoch No : 4\n",
      "300/300 [==============================] - ETA: 0s - loss: 4.0443\n",
      "Epoch 1: loss improved from 4.34320 to 4.04429, saving model to E:\\uniSlides\\CS\\Research\\FinalDataset\\FinalData\\unique_2VGG_FINAL\\\\training_2\\cp.ckpt\n",
      "300/300 [==============================] - 550s 2s/step - loss: 4.0443\n",
      "Epoch No : 5\n",
      "300/300 [==============================] - ETA: 0s - loss: 3.9380\n",
      "Epoch 1: loss improved from 4.04429 to 3.93800, saving model to E:\\uniSlides\\CS\\Research\\FinalDataset\\FinalData\\unique_2VGG_FINAL\\\\training_2\\cp.ckpt\n",
      "300/300 [==============================] - 548s 2s/step - loss: 3.9380\n",
      "Epoch No : 6\n",
      "300/300 [==============================] - ETA: 0s - loss: 3.6845\n",
      "Epoch 1: loss improved from 3.93800 to 3.68447, saving model to E:\\uniSlides\\CS\\Research\\FinalDataset\\FinalData\\unique_2VGG_FINAL\\\\training_2\\cp.ckpt\n",
      "300/300 [==============================] - 552s 2s/step - loss: 3.6845\n",
      "Epoch No : 7\n",
      "300/300 [==============================] - ETA: 0s - loss: 3.5118\n",
      "Epoch 1: loss improved from 3.68447 to 3.51176, saving model to E:\\uniSlides\\CS\\Research\\FinalDataset\\FinalData\\unique_2VGG_FINAL\\\\training_2\\cp.ckpt\n",
      "300/300 [==============================] - 553s 2s/step - loss: 3.5118\n",
      "Epoch No : 8\n",
      "300/300 [==============================] - ETA: 0s - loss: 3.4205\n",
      "Epoch 1: loss improved from 3.51176 to 3.42054, saving model to E:\\uniSlides\\CS\\Research\\FinalDataset\\FinalData\\unique_2VGG_FINAL\\\\training_2\\cp.ckpt\n",
      "300/300 [==============================] - 551s 2s/step - loss: 3.4205\n",
      "Epoch No : 9\n",
      "300/300 [==============================] - ETA: 0s - loss: 3.1673\n",
      "Epoch 1: loss improved from 3.42054 to 3.16732, saving model to E:\\uniSlides\\CS\\Research\\FinalDataset\\FinalData\\unique_2VGG_FINAL\\\\training_2\\cp.ckpt\n",
      "300/300 [==============================] - 553s 2s/step - loss: 3.1673\n",
      "Epoch No : 10\n",
      "300/300 [==============================] - ETA: 0s - loss: 2.9671\n",
      "Epoch 1: loss improved from 3.16732 to 2.96714, saving model to E:\\uniSlides\\CS\\Research\\FinalDataset\\FinalData\\unique_2VGG_FINAL\\\\training_2\\cp.ckpt\n",
      "300/300 [==============================] - 550s 2s/step - loss: 2.9671\n",
      "Epoch No : 11\n",
      "300/300 [==============================] - ETA: 0s - loss: 2.8394\n",
      "Epoch 1: loss improved from 2.96714 to 2.83942, saving model to E:\\uniSlides\\CS\\Research\\FinalDataset\\FinalData\\unique_2VGG_FINAL\\\\training_2\\cp.ckpt\n",
      "300/300 [==============================] - 550s 2s/step - loss: 2.8394\n",
      "Epoch No : 12\n",
      "300/300 [==============================] - ETA: 0s - loss: 2.7684\n",
      "Epoch 1: loss improved from 2.83942 to 2.76842, saving model to E:\\uniSlides\\CS\\Research\\FinalDataset\\FinalData\\unique_2VGG_FINAL\\\\training_2\\cp.ckpt\n",
      "300/300 [==============================] - 550s 2s/step - loss: 2.7684\n",
      "Epoch No : 13\n",
      "300/300 [==============================] - ETA: 0s - loss: 2.7403\n",
      "Epoch 1: loss improved from 2.76842 to 2.74029, saving model to E:\\uniSlides\\CS\\Research\\FinalDataset\\FinalData\\unique_2VGG_FINAL\\\\training_2\\cp.ckpt\n",
      "300/300 [==============================] - 554s 2s/step - loss: 2.7403\n",
      "Epoch No : 14\n",
      "300/300 [==============================] - ETA: 0s - loss: 2.7358\n",
      "Epoch 1: loss improved from 2.74029 to 2.73576, saving model to E:\\uniSlides\\CS\\Research\\FinalDataset\\FinalData\\unique_2VGG_FINAL\\\\training_2\\cp.ckpt\n",
      "300/300 [==============================] - 554s 2s/step - loss: 2.7358\n",
      "Epoch No : 15\n",
      "300/300 [==============================] - ETA: 0s - loss: 2.5866\n",
      "Epoch 1: loss improved from 2.73576 to 2.58663, saving model to E:\\uniSlides\\CS\\Research\\FinalDataset\\FinalData\\unique_2VGG_FINAL\\\\training_2\\cp.ckpt\n",
      "300/300 [==============================] - 556s 2s/step - loss: 2.5866\n",
      "Epoch No : 16\n",
      "300/300 [==============================] - ETA: 0s - loss: 2.4083\n",
      "Epoch 1: loss improved from 2.58663 to 2.40829, saving model to E:\\uniSlides\\CS\\Research\\FinalDataset\\FinalData\\unique_2VGG_FINAL\\\\training_2\\cp.ckpt\n",
      "300/300 [==============================] - 554s 2s/step - loss: 2.4083\n",
      "Epoch No : 17\n",
      "300/300 [==============================] - ETA: 0s - loss: 2.3462\n",
      "Epoch 1: loss improved from 2.40829 to 2.34616, saving model to E:\\uniSlides\\CS\\Research\\FinalDataset\\FinalData\\unique_2VGG_FINAL\\\\training_2\\cp.ckpt\n",
      "300/300 [==============================] - 555s 2s/step - loss: 2.3462\n",
      "Epoch No : 18\n",
      "300/300 [==============================] - ETA: 0s - loss: 2.3512\n",
      "Epoch 1: loss did not improve from 2.34616\n",
      "300/300 [==============================] - 553s 2s/step - loss: 2.3512\n",
      "Epoch No : 19\n",
      "300/300 [==============================] - ETA: 0s - loss: 2.2365\n",
      "Epoch 1: loss improved from 2.34616 to 2.23655, saving model to E:\\uniSlides\\CS\\Research\\FinalDataset\\FinalData\\unique_2VGG_FINAL\\\\training_2\\cp.ckpt\n",
      "300/300 [==============================] - 555s 2s/step - loss: 2.2365\n",
      "Epoch No : 20\n",
      "300/300 [==============================] - ETA: 0s - loss: 2.1768\n",
      "Epoch 1: loss improved from 2.23655 to 2.17677, saving model to E:\\uniSlides\\CS\\Research\\FinalDataset\\FinalData\\unique_2VGG_FINAL\\\\training_2\\cp.ckpt\n",
      "300/300 [==============================] - 552s 2s/step - loss: 2.1768\n",
      "Epoch No : 21\n",
      "300/300 [==============================] - ETA: 0s - loss: 2.0134\n",
      "Epoch 1: loss improved from 2.17677 to 2.01335, saving model to E:\\uniSlides\\CS\\Research\\FinalDataset\\FinalData\\unique_2VGG_FINAL\\\\training_2\\cp.ckpt\n",
      "300/300 [==============================] - 550s 2s/step - loss: 2.0134\n",
      "Epoch No : 22\n",
      "300/300 [==============================] - ETA: 0s - loss: 2.0277\n",
      "Epoch 1: loss did not improve from 2.01335\n",
      "300/300 [==============================] - 553s 2s/step - loss: 2.0277\n",
      "Epoch No : 23\n",
      "300/300 [==============================] - ETA: 0s - loss: 1.9391\n",
      "Epoch 1: loss improved from 2.01335 to 1.93910, saving model to E:\\uniSlides\\CS\\Research\\FinalDataset\\FinalData\\unique_2VGG_FINAL\\\\training_2\\cp.ckpt\n",
      "300/300 [==============================] - 560s 2s/step - loss: 1.9391\n",
      "Epoch No : 24\n",
      "300/300 [==============================] - ETA: 0s - loss: 1.8731\n",
      "Epoch 1: loss improved from 1.93910 to 1.87307, saving model to E:\\uniSlides\\CS\\Research\\FinalDataset\\FinalData\\unique_2VGG_FINAL\\\\training_2\\cp.ckpt\n",
      "300/300 [==============================] - 556s 2s/step - loss: 1.8731\n",
      "Epoch No : 25\n",
      "300/300 [==============================] - ETA: 0s - loss: 1.7655\n",
      "Epoch 1: loss improved from 1.87307 to 1.76552, saving model to E:\\uniSlides\\CS\\Research\\FinalDataset\\FinalData\\unique_2VGG_FINAL\\\\training_2\\cp.ckpt\n",
      "300/300 [==============================] - 556s 2s/step - loss: 1.7655\n",
      "Epoch No : 26\n",
      "300/300 [==============================] - ETA: 0s - loss: 1.6956\n",
      "Epoch 1: loss improved from 1.76552 to 1.69557, saving model to E:\\uniSlides\\CS\\Research\\FinalDataset\\FinalData\\unique_2VGG_FINAL\\\\training_2\\cp.ckpt\n",
      "300/300 [==============================] - 557s 2s/step - loss: 1.6956\n",
      "Epoch No : 27\n",
      "300/300 [==============================] - ETA: 0s - loss: 1.6042\n",
      "Epoch 1: loss improved from 1.69557 to 1.60419, saving model to E:\\uniSlides\\CS\\Research\\FinalDataset\\FinalData\\unique_2VGG_FINAL\\\\training_2\\cp.ckpt\n",
      "300/300 [==============================] - 563s 2s/step - loss: 1.6042\n",
      "Epoch No : 28\n",
      "300/300 [==============================] - ETA: 0s - loss: 1.5062\n",
      "Epoch 1: loss improved from 1.60419 to 1.50616, saving model to E:\\uniSlides\\CS\\Research\\FinalDataset\\FinalData\\unique_2VGG_FINAL\\\\training_2\\cp.ckpt\n",
      "300/300 [==============================] - 565s 2s/step - loss: 1.5062\n",
      "Epoch No : 29\n",
      "300/300 [==============================] - ETA: 0s - loss: 1.4548\n",
      "Epoch 1: loss improved from 1.50616 to 1.45481, saving model to E:\\uniSlides\\CS\\Research\\FinalDataset\\FinalData\\unique_2VGG_FINAL\\\\training_2\\cp.ckpt\n",
      "300/300 [==============================] - 560s 2s/step - loss: 1.4548\n",
      "Epoch No : 30\n",
      "300/300 [==============================] - ETA: 0s - loss: 1.4841\n",
      "Epoch 1: loss did not improve from 1.45481\n",
      "300/300 [==============================] - 554s 2s/step - loss: 1.4841\n",
      "Epoch No : 31\n",
      "300/300 [==============================] - ETA: 0s - loss: 1.2836\n",
      "Epoch 1: loss improved from 1.45481 to 1.28365, saving model to E:\\uniSlides\\CS\\Research\\FinalDataset\\FinalData\\unique_2VGG_FINAL\\\\training_2\\cp.ckpt\n",
      "300/300 [==============================] - 555s 2s/step - loss: 1.2836\n",
      "Epoch No : 32\n",
      "300/300 [==============================] - ETA: 0s - loss: 1.2345\n",
      "Epoch 1: loss improved from 1.28365 to 1.23453, saving model to E:\\uniSlides\\CS\\Research\\FinalDataset\\FinalData\\unique_2VGG_FINAL\\\\training_2\\cp.ckpt\n",
      "300/300 [==============================] - 556s 2s/step - loss: 1.2345\n",
      "Epoch No : 33\n",
      "300/300 [==============================] - ETA: 0s - loss: 1.1681\n",
      "Epoch 1: loss improved from 1.23453 to 1.16806, saving model to E:\\uniSlides\\CS\\Research\\FinalDataset\\FinalData\\unique_2VGG_FINAL\\\\training_2\\cp.ckpt\n",
      "300/300 [==============================] - 561s 2s/step - loss: 1.1681\n",
      "Epoch No : 34\n",
      "300/300 [==============================] - ETA: 0s - loss: 1.1070\n",
      "Epoch 1: loss improved from 1.16806 to 1.10703, saving model to E:\\uniSlides\\CS\\Research\\FinalDataset\\FinalData\\unique_2VGG_FINAL\\\\training_2\\cp.ckpt\n",
      "300/300 [==============================] - 558s 2s/step - loss: 1.1070\n",
      "Epoch No : 35\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.9914\n",
      "Epoch 1: loss improved from 1.10703 to 0.99144, saving model to E:\\uniSlides\\CS\\Research\\FinalDataset\\FinalData\\unique_2VGG_FINAL\\\\training_2\\cp.ckpt\n",
      "300/300 [==============================] - 557s 2s/step - loss: 0.9914\n",
      "Epoch No : 36\n",
      "300/300 [==============================] - ETA: 0s - loss: 1.0179\n",
      "Epoch 1: loss did not improve from 0.99144\n",
      "300/300 [==============================] - 556s 2s/step - loss: 1.0179\n",
      "Epoch No : 37\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.8896\n",
      "Epoch 1: loss improved from 0.99144 to 0.88961, saving model to E:\\uniSlides\\CS\\Research\\FinalDataset\\FinalData\\unique_2VGG_FINAL\\\\training_2\\cp.ckpt\n",
      "300/300 [==============================] - 557s 2s/step - loss: 0.8896\n",
      "Epoch No : 38\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.8758\n",
      "Epoch 1: loss improved from 0.88961 to 0.87577, saving model to E:\\uniSlides\\CS\\Research\\FinalDataset\\FinalData\\unique_2VGG_FINAL\\\\training_2\\cp.ckpt\n",
      "300/300 [==============================] - 557s 2s/step - loss: 0.8758\n",
      "Epoch No : 39\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.8595\n",
      "Epoch 1: loss improved from 0.87577 to 0.85949, saving model to E:\\uniSlides\\CS\\Research\\FinalDataset\\FinalData\\unique_2VGG_FINAL\\\\training_2\\cp.ckpt\n",
      "300/300 [==============================] - 561s 2s/step - loss: 0.8595\n",
      "Epoch No : 40\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.7391\n",
      "Epoch 1: loss improved from 0.85949 to 0.73910, saving model to E:\\uniSlides\\CS\\Research\\FinalDataset\\FinalData\\unique_2VGG_FINAL\\\\training_2\\cp.ckpt\n",
      "300/300 [==============================] - 558s 2s/step - loss: 0.7391\n",
      "Epoch No : 41\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.6943\n",
      "Epoch 1: loss improved from 0.73910 to 0.69428, saving model to E:\\uniSlides\\CS\\Research\\FinalDataset\\FinalData\\unique_2VGG_FINAL\\\\training_2\\cp.ckpt\n",
      "300/300 [==============================] - 803s 3s/step - loss: 0.6943\n",
      "Epoch No : 42\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.5966\n",
      "Epoch 1: loss improved from 0.69428 to 0.59656, saving model to E:\\uniSlides\\CS\\Research\\FinalDataset\\FinalData\\unique_2VGG_FINAL\\\\training_2\\cp.ckpt\n",
      "300/300 [==============================] - 729s 2s/step - loss: 0.5966\n",
      "Epoch No : 43\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.5658\n",
      "Epoch 1: loss improved from 0.59656 to 0.56580, saving model to E:\\uniSlides\\CS\\Research\\FinalDataset\\FinalData\\unique_2VGG_FINAL\\\\training_2\\cp.ckpt\n",
      "300/300 [==============================] - 618s 2s/step - loss: 0.5658\n",
      "Epoch No : 44\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.5345\n",
      "Epoch 1: loss improved from 0.56580 to 0.53451, saving model to E:\\uniSlides\\CS\\Research\\FinalDataset\\FinalData\\unique_2VGG_FINAL\\\\training_2\\cp.ckpt\n",
      "300/300 [==============================] - 589s 2s/step - loss: 0.5345\n",
      "Epoch No : 45\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.5362\n",
      "Epoch 1: loss did not improve from 0.53451\n",
      "300/300 [==============================] - 591s 2s/step - loss: 0.5362\n",
      "Epoch No : 46\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.5003\n",
      "Epoch 1: loss improved from 0.53451 to 0.50030, saving model to E:\\uniSlides\\CS\\Research\\FinalDataset\\FinalData\\unique_2VGG_FINAL\\\\training_2\\cp.ckpt\n",
      "300/300 [==============================] - 593s 2s/step - loss: 0.5003\n",
      "Epoch No : 47\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.4433\n",
      "Epoch 1: loss improved from 0.50030 to 0.44333, saving model to E:\\uniSlides\\CS\\Research\\FinalDataset\\FinalData\\unique_2VGG_FINAL\\\\training_2\\cp.ckpt\n",
      "300/300 [==============================] - 588s 2s/step - loss: 0.4433\n",
      "Epoch No : 48\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.4632\n",
      "Epoch 1: loss did not improve from 0.44333\n",
      "300/300 [==============================] - 589s 2s/step - loss: 0.4632\n",
      "Epoch No : 49\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.4700\n",
      "Epoch 1: loss did not improve from 0.44333\n",
      "300/300 [==============================] - 607s 2s/step - loss: 0.4700\n",
      "Epoch No : 50\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.5065\n",
      "Epoch 1: loss did not improve from 0.44333\n",
      "300/300 [==============================] - 614s 2s/step - loss: 0.5065\n",
      "Epoch No : 51\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.5644\n",
      "Epoch 1: loss did not improve from 0.44333\n",
      "300/300 [==============================] - 616s 2s/step - loss: 0.5644\n",
      "Epoch No : 52\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.4380\n",
      "Epoch 1: loss improved from 0.44333 to 0.43800, saving model to E:\\uniSlides\\CS\\Research\\FinalDataset\\FinalData\\unique_2VGG_FINAL\\\\training_2\\cp.ckpt\n",
      "300/300 [==============================] - 621s 2s/step - loss: 0.4380\n",
      "Epoch No : 53\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.3415\n",
      "Epoch 1: loss improved from 0.43800 to 0.34148, saving model to E:\\uniSlides\\CS\\Research\\FinalDataset\\FinalData\\unique_2VGG_FINAL\\\\training_2\\cp.ckpt\n",
      "300/300 [==============================] - 618s 2s/step - loss: 0.3415\n",
      "Epoch No : 54\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2908\n",
      "Epoch 1: loss improved from 0.34148 to 0.29077, saving model to E:\\uniSlides\\CS\\Research\\FinalDataset\\FinalData\\unique_2VGG_FINAL\\\\training_2\\cp.ckpt\n",
      "300/300 [==============================] - 620s 2s/step - loss: 0.2908\n",
      "Epoch No : 55\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.3247\n",
      "Epoch 1: loss did not improve from 0.29077\n",
      "300/300 [==============================] - 620s 2s/step - loss: 0.3247\n",
      "Epoch No : 56\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2615\n",
      "Epoch 1: loss improved from 0.29077 to 0.26150, saving model to E:\\uniSlides\\CS\\Research\\FinalDataset\\FinalData\\unique_2VGG_FINAL\\\\training_2\\cp.ckpt\n",
      "300/300 [==============================] - 614s 2s/step - loss: 0.2615\n",
      "Epoch No : 57\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2373\n",
      "Epoch 1: loss improved from 0.26150 to 0.23726, saving model to E:\\uniSlides\\CS\\Research\\FinalDataset\\FinalData\\unique_2VGG_FINAL\\\\training_2\\cp.ckpt\n",
      "300/300 [==============================] - 611s 2s/step - loss: 0.2373\n",
      "Epoch No : 58\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.1881\n",
      "Epoch 1: loss improved from 0.23726 to 0.18806, saving model to E:\\uniSlides\\CS\\Research\\FinalDataset\\FinalData\\unique_2VGG_FINAL\\\\training_2\\cp.ckpt\n",
      "300/300 [==============================] - 613s 2s/step - loss: 0.1881\n",
      "Epoch No : 59\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.1663\n",
      "Epoch 1: loss improved from 0.18806 to 0.16630, saving model to E:\\uniSlides\\CS\\Research\\FinalDataset\\FinalData\\unique_2VGG_FINAL\\\\training_2\\cp.ckpt\n",
      "300/300 [==============================] - 618s 2s/step - loss: 0.1663\n",
      "Epoch No : 60\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.1595\n",
      "Epoch 1: loss improved from 0.16630 to 0.15950, saving model to E:\\uniSlides\\CS\\Research\\FinalDataset\\FinalData\\unique_2VGG_FINAL\\\\training_2\\cp.ckpt\n",
      "300/300 [==============================] - 618s 2s/step - loss: 0.1595\n",
      "Epoch No : 61\n",
      "280/300 [===========================>..] - ETA: 41s - loss: 0.1526"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [202]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m#fit model for one epoch\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch No : \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m----> 6\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cpuml\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cpuml\\lib\\site-packages\\keras\\engine\\training.py:1384\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1377\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1378\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   1379\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   1380\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[0;32m   1381\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m   1382\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m   1383\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1384\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1385\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1386\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cpuml\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cpuml\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cpuml\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cpuml\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2956\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2953\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2954\u001b[0m   (graph_function,\n\u001b[0;32m   2955\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2956\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2957\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cpuml\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1853\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1849\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1850\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1851\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1852\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1853\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1854\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1855\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1856\u001b[0m     args,\n\u001b[0;32m   1857\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1858\u001b[0m     executing_eagerly)\n\u001b[0;32m   1859\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cpuml\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cpuml\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(epochs):\n",
    "  #create data generator\n",
    "  generator  = data_generator(train_midi, train_features, tokenizer, maxLength, vocabSize)\n",
    "  #fit model for one epoch\n",
    "  print(\"Epoch No : \" + str(i + 1))\n",
    "  model.fit(generator, epochs=1, steps_per_epoch=steps, callbacks=[checkpoint], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#resume training\n",
    "#load weights\n",
    "filepath = data_dir + 'training_2/cp.ckpt'\n",
    "checkpoint_dir = os.path.dirname(filepath)\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_weights_only=True, save_best_only=True, mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Summary\n",
      "Model: \"model_8\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_16 (InputLayer)          [(None, 114)]        0           []                               \n",
      "                                                                                                  \n",
      " embedding_6 (Embedding)        (None, 114, 256)     87040       ['input_16[0][0]']               \n",
      "                                                                                                  \n",
      " dropout_19 (Dropout)           (None, 114, 256)     0           ['embedding_6[0][0]']            \n",
      "                                                                                                  \n",
      " input_15 (InputLayer)          [(None, 4096)]       0           []                               \n",
      "                                                                                                  \n",
      " lstm_12 (LSTM)                 (None, 114, 128)     197120      ['dropout_19[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_18 (Dropout)           (None, 4096)         0           ['input_15[0][0]']               \n",
      "                                                                                                  \n",
      " dropout_20 (Dropout)           (None, 114, 128)     0           ['lstm_12[0][0]']                \n",
      "                                                                                                  \n",
      " dense_18 (Dense)               (None, 256)          1048832     ['dropout_18[0][0]']             \n",
      "                                                                                                  \n",
      " lstm_13 (LSTM)                 (None, 256)          394240      ['dropout_20[0][0]']             \n",
      "                                                                                                  \n",
      " add_6 (Add)                    (None, 256)          0           ['dense_18[0][0]',               \n",
      "                                                                  'lstm_13[0][0]']                \n",
      "                                                                                                  \n",
      " dense_19 (Dense)               (None, 256)          65792       ['add_6[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_20 (Dense)               (None, 340)          87380       ['dense_19[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,880,404\n",
      "Trainable params: 1,880,404\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_Model(vocabSize, maxLength)\n",
    "model.load_weights(filepath)\n",
    "tokenizer = load(open(data_dir + 'tokenizer.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch No : 1\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.1473\n",
      "Epoch 1: loss improved from 0.15950 to 0.14733, saving model to E:\\uniSlides\\CS\\Research\\FinalDataset\\FinalData\\unique_2VGG_FINAL\\\\training_2\\cp.ckpt\n",
      "300/300 [==============================] - 628s 2s/step - loss: 0.1473\n",
      "Epoch No : 2\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.1515\n",
      "Epoch 1: loss did not improve from 0.14733\n",
      "300/300 [==============================] - 601s 2s/step - loss: 0.1515\n",
      "Epoch No : 3\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.1961\n",
      "Epoch 1: loss did not improve from 0.14733\n",
      "300/300 [==============================] - 592s 2s/step - loss: 0.1961\n",
      "Epoch No : 4\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2248\n",
      "Epoch 1: loss did not improve from 0.14733\n",
      "300/300 [==============================] - 591s 2s/step - loss: 0.2248\n",
      "Epoch No : 5\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2403\n",
      "Epoch 1: loss did not improve from 0.14733\n",
      "300/300 [==============================] - 583s 2s/step - loss: 0.2403\n",
      "Epoch No : 6\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2299\n",
      "Epoch 1: loss did not improve from 0.14733\n",
      "300/300 [==============================] - 589s 2s/step - loss: 0.2299\n",
      "Epoch No : 7\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2489\n",
      "Epoch 1: loss did not improve from 0.14733\n",
      "300/300 [==============================] - 591s 2s/step - loss: 0.2489\n",
      "Epoch No : 8\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.1812\n",
      "Epoch 1: loss did not improve from 0.14733\n",
      "300/300 [==============================] - 589s 2s/step - loss: 0.1812\n",
      "Epoch No : 9\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.1524\n",
      "Epoch 1: loss did not improve from 0.14733\n",
      "300/300 [==============================] - 592s 2s/step - loss: 0.1524\n",
      "Epoch No : 10\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.1557\n",
      "Epoch 1: loss did not improve from 0.14733\n",
      "300/300 [==============================] - 604s 2s/step - loss: 0.1557\n",
      "Epoch No : 11\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.1352\n",
      "Epoch 1: loss improved from 0.14733 to 0.13522, saving model to E:\\uniSlides\\CS\\Research\\FinalDataset\\FinalData\\unique_2VGG_FINAL\\\\training_2\\cp.ckpt\n",
      "300/300 [==============================] - 592s 2s/step - loss: 0.1352\n",
      "Epoch No : 12\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.1466\n",
      "Epoch 1: loss did not improve from 0.13522\n",
      "300/300 [==============================] - 594s 2s/step - loss: 0.1466\n",
      "Epoch No : 13\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.1401\n",
      "Epoch 1: loss did not improve from 0.13522\n",
      "300/300 [==============================] - 595s 2s/step - loss: 0.1401\n",
      "Epoch No : 14\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.1176\n",
      "Epoch 1: loss improved from 0.13522 to 0.11755, saving model to E:\\uniSlides\\CS\\Research\\FinalDataset\\FinalData\\unique_2VGG_FINAL\\\\training_2\\cp.ckpt\n",
      "300/300 [==============================] - 600s 2s/step - loss: 0.1176\n",
      "Epoch No : 15\n",
      " 20/300 [=>............................] - ETA: 9:53 - loss: 0.0679 "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [204]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m#fit model for one epoch\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch No : \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m----> 6\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cpuml\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cpuml\\lib\\site-packages\\keras\\engine\\training.py:1384\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1377\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1378\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   1379\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   1380\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[0;32m   1381\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m   1382\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m   1383\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1384\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1385\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1386\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cpuml\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cpuml\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cpuml\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cpuml\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2956\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2953\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2954\u001b[0m   (graph_function,\n\u001b[0;32m   2955\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2956\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2957\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cpuml\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1853\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1849\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1850\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1851\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1852\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1853\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1854\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1855\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1856\u001b[0m     args,\n\u001b[0;32m   1857\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1858\u001b[0m     executing_eagerly)\n\u001b[0;32m   1859\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cpuml\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cpuml\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(epochs):\n",
    "  #create data generator\n",
    "  generator = data_generator(train_midi, train_features, tokenizer, maxLength, vocabSize)\n",
    "  #fit model for one epoch\n",
    "  print(\"Epoch No : \" + str(i + 1))\n",
    "  model.fit(generator, epochs=1, steps_per_epoch=steps, callbacks=[checkpoint], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#resume training\n",
    "#load weights\n",
    "filepath = data_dir + 'training_2/cp.ckpt'\n",
    "checkpoint_dir = os.path.dirname(filepath)\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_weights_only=True, save_best_only=True, mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Summary\n",
      "Model: \"model_50\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_72 (InputLayer)          [(None, 114)]        0           []                               \n",
      "                                                                                                  \n",
      " embedding_20 (Embedding)       (None, 114, 256)     87040       ['input_72[0][0]']               \n",
      "                                                                                                  \n",
      " dropout_61 (Dropout)           (None, 114, 256)     0           ['embedding_20[0][0]']           \n",
      "                                                                                                  \n",
      " input_71 (InputLayer)          [(None, 4096)]       0           []                               \n",
      "                                                                                                  \n",
      " lstm_40 (LSTM)                 (None, 114, 128)     197120      ['dropout_61[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_60 (Dropout)           (None, 4096)         0           ['input_71[0][0]']               \n",
      "                                                                                                  \n",
      " dropout_62 (Dropout)           (None, 114, 128)     0           ['lstm_40[0][0]']                \n",
      "                                                                                                  \n",
      " dense_60 (Dense)               (None, 256)          1048832     ['dropout_60[0][0]']             \n",
      "                                                                                                  \n",
      " lstm_41 (LSTM)                 (None, 256)          394240      ['dropout_62[0][0]']             \n",
      "                                                                                                  \n",
      " add_20 (Add)                   (None, 256)          0           ['dense_60[0][0]',               \n",
      "                                                                  'lstm_41[0][0]']                \n",
      "                                                                                                  \n",
      " dense_61 (Dense)               (None, 256)          65792       ['add_20[0][0]']                 \n",
      "                                                                                                  \n",
      " dense_62 (Dense)               (None, 340)          87380       ['dense_61[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,880,404\n",
      "Trainable params: 1,880,404\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_Model(vocabSize, maxLength)\n",
    "model.load_weights(filepath)\n",
    "tokenizer = load(open(data_dir + 'tokenizer.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch No : 1\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.1251\n",
      "Epoch 1: loss improved from inf to 0.12512, saving model to E:\\uniSlides\\CS\\Research\\FinalDataset\\FinalData\\unique_2VGG_FINAL\\\\training_2\\cp.ckpt\n",
      "300/300 [==============================] - 958s 3s/step - loss: 0.1251\n",
      "Epoch No : 2\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.1025\n",
      "Epoch 1: loss improved from 0.12512 to 0.10249, saving model to E:\\uniSlides\\CS\\Research\\FinalDataset\\FinalData\\unique_2VGG_FINAL\\\\training_2\\cp.ckpt\n",
      "300/300 [==============================] - 871s 3s/step - loss: 0.1025\n",
      "Epoch No : 3\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.1026\n",
      "Epoch 1: loss did not improve from 0.10249\n",
      "300/300 [==============================] - 885s 3s/step - loss: 0.1026\n",
      "Epoch No : 4\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.1393\n",
      "Epoch 1: loss did not improve from 0.10249\n",
      "300/300 [==============================] - 775s 3s/step - loss: 0.1393\n",
      "Epoch No : 5\n",
      "191/300 [==================>...........] - ETA: 4:11 - loss: 0.1141"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [87]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m#fit model for one epoch\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch No : \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m----> 6\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cpuml\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cpuml\\lib\\site-packages\\keras\\engine\\training.py:1384\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1377\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1378\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   1379\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   1380\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[0;32m   1381\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m   1382\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m   1383\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1384\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1385\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1386\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cpuml\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cpuml\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cpuml\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cpuml\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2956\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2953\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2954\u001b[0m   (graph_function,\n\u001b[0;32m   2955\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2956\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2957\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cpuml\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1853\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1849\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1850\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1851\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1852\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1853\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1854\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1855\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1856\u001b[0m     args,\n\u001b[0;32m   1857\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1858\u001b[0m     executing_eagerly)\n\u001b[0;32m   1859\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cpuml\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cpuml\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(epochs):\n",
    "  #create data generator\n",
    "  generator = data_generator(train_midi, train_features, tokenizer, maxLength, vocabSize)\n",
    "  #fit model for one epoch\n",
    "  print(\"Epoch No : \" + str(i + 1))\n",
    "  model.fit(generator, epochs=1, steps_per_epoch=steps, callbacks=[checkpoint], verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IofOV9EcZDvw"
   },
   "source": [
    "Generate a melody for a test image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_wi_WbXPZImK",
    "outputId": "fb9cf273-59b4-4e2c-bfc1-ade971b732fb",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Summary\n",
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_8 (InputLayer)           [(None, 114)]        0           []                               \n",
      "                                                                                                  \n",
      " embedding_3 (Embedding)        (None, 114, 256)     87040       ['input_8[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_10 (Dropout)           (None, 114, 256)     0           ['embedding_3[0][0]']            \n",
      "                                                                                                  \n",
      " input_7 (InputLayer)           [(None, 4096)]       0           []                               \n",
      "                                                                                                  \n",
      " lstm_6 (LSTM)                  (None, 114, 128)     197120      ['dropout_10[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_9 (Dropout)            (None, 4096)         0           ['input_7[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_11 (Dropout)           (None, 114, 128)     0           ['lstm_6[0][0]']                 \n",
      "                                                                                                  \n",
      " dense_9 (Dense)                (None, 256)          1048832     ['dropout_9[0][0]']              \n",
      "                                                                                                  \n",
      " lstm_7 (LSTM)                  (None, 256)          394240      ['dropout_11[0][0]']             \n",
      "                                                                                                  \n",
      " add_3 (Add)                    (None, 256)          0           ['dense_9[0][0]',                \n",
      "                                                                  'lstm_7[0][0]']                 \n",
      "                                                                                                  \n",
      " dense_10 (Dense)               (None, 256)          65792       ['add_3[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_11 (Dense)               (None, 340)          87380       ['dense_10[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,880,404\n",
      "Trainable params: 1,880,404\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Midi Sequnce in text\n",
      "<start> 143.0@tempo 4/4@time r@1.0 a5@0.5 b5@0.5 c6@0.5 b5@0.5 a5@1.0 r@1.5 a5@0.5 c6@1.0 c6@1.0 r@1.5 a5@0.5 c6@0.5 b5@0.5 a5@0.75 r@0.25 r@0.5 a5@0.5 a5@0.25 r@0.25 a5@0.5 c6@0.5 a5@0.5 c6@2/3 r@1/3 r@1.5 e5@0.5 b5@0.5 a5@0.5 g5@0.75 r@0.25 r@1.5 e5@0.5 g5@0.75 r@0.25 g5@1.0 r@4.0 r@4.0 <end>\n",
      "Saving Output file as midi....\n",
      "Midi Sequnce in text\n",
      "<start> 125.0@tempo 4/4@time r@0.5 c5@0.25 c5@0.25 d4@0.25 r@0.25 e4@0.25 r@0.25 e4@0.25 r@0.25 d4@1.0 c4@1.0 e3@1.0 b4@1.0 b4@1.0 r@2.0 r@4.0 r@4.0 r@3.0 r@1/6 e4@0.5 c4@0.5 d4@0.5 c4@0.5 d4@0.5 c4@1.0 e4@1.0 d4@1.0 c4@1.0 c5@0.25 r@0.25 c4@3.5 r@0.5 <end>\n",
      "Saving Output file as midi....\n",
      "Midi Sequnce in text\n",
      "<start> 65.0@tempo 4/4@time a4@1.25 r@0.5 e4@0.25 d4@0.25 c4@0.25 e4@1.25 r@0.25 r@0.25 a3@0.25 c4@0.25 d4@0.25 e4@0.25 e4@0.25 r@0.25 e4@0.25 d4@0.25 c4@0.25 e4@0.75 r@0.75 e5@4/3 r@5/12 b4@0.25 a4@0.25 g4@0.25 b4@1.25 r@0.25 r@0.25 e4@0.25 g4@0.25 a4@0.25 b4@0.25 b4@0.25 r@0.25 b4@0.25 b4@0.25 r@0.25 b4@0.25 a4@1/3 g4@0.25 b4@1.0 r@0.5 a4@4/3 r@5/12 e4@0.25 d4@0.25 c4@0.25 e4@1.5 r@0.25 a3@0.25 c4@1/3 d4@1/3 e4@0.25 e4@0.25 r@0.25 e4@0.25 d4@0.25 c4@0.25 e4@0.75 r@0.75 e5@4/3 r@5/12 b4@0.25 a4@1/3 g4@0.25 b4@1.5 r@0.25 e4@0.25 g4@0.25 a4@0.25 b4@0.25 b4@0.25 r@0.25 b4@0.25 a4@1/3 g4@0.25 b4@1.0 r@0.5 a4@4/3 r@5/12 e4@0.25 d4@0.25 c4@0.25 e4@1.5 r@0.25 a3@0.25 c4@1/3 d4@1/3 e4@0.25 e4@0.25 r@0.25 e4@0.25 d4@0.25 c4@0.25 e4@0.75 r@0.75 e5@4/3 r@5/12 b4@0.25 a4@1/3 g4@0.25 b4@1.5 r@0.25 e4@0.25 g4@0.25 a4@0.25 b4@0.25 b4@0.25 r@0.25 b4@0.25 a4@1/3 g4@0.25 b4@1.0\n",
      "Saving Output file as midi....\n",
      "Midi Sequnce in text\n",
      "<start> 120.0@tempo 4/4@time r@0.5 a4@0.5 a4@0.5 a4@0.5 a4@0.25 f#4@0.25 e4@0.5 e5@0.5 r@1.0 d4@0.5 d4@0.5 e4@0.5 e4@0.5 e4@0.5 d4@0.5 d4@0.5 r@2.5 e4@0.5 d4@1.0 b4@0.5 r@0.5 e5@1.0 r@1.0 d4@0.5 d4@0.5 e4@0.5 e4@0.5 r@2.5 r@0.5 f#4@0.5 f#4@0.5 f#4@0.5 f#4@0.5 d4@0.5 d4@0.5 b3@0.5 c4@0.5 r@0.5 c4@1.0 r@5/6 d5@0.5 a4@0.5 c5@0.25 r@0.5 a4@0.5 b4@0.5 g#4@0.5 e4@0.25 r@0.25 b4@0.5 d4@0.25 r@2.25 g4@0.5 r@2.25 <end>\n",
      "Saving Output file as midi....\n",
      "Midi Sequnce in text\n",
      "<start> 150.0@tempo 4/4@time r@1.0 g3@2/3 r@1/3 g3@2/3 r@1/3 g3@0.5 a3@0.5 a3@2.0 g3@2.0 r@1.0 g3@2/3 r@1/3 g3@2/3 r@1/3 g3@2/3 r@1/3 f#3@1/3 r@0.25 g3@1.75 r@5/3 r@2.0 r@0.25 f3@0.25 r@0.25 f3@0.25 r@0.25 f3@2.0 e3@1.5 g3@0.5 e-3@1/3 r@0.25 e3@1.75 r@5/3 d3@2.0 r@2.0 r@1.0 r@3.5 c3@2/3 r@1/3 c3@2/3 r@1/3 c3@1/3 c#3@0.25 d3@0.5 r@5/12 d3@2.0 7.9.11.0@0.25 r@2.0 <end>\n",
      "Saving Output file as midi....\n",
      "Midi Sequnce in text\n",
      "<start> 123.0@tempo 4/4@time e3@0.25 r@0.25 e3@0.25 r@0.25 e3@2/3 r@1/3 d3@0.5 r@0.5 e3@1.0 e3@1.75 r@2.25 e3@1/3 r@1/3 e3@0.25 r@1/12 e3@2/3 d3@1/3 r@2/3 c3@1.0 c3@2/3 r@2.0 e3@0.25 r@1/12 g3@2/3 a3@1/3 e3@0.25 r@0.25 e3@0.25 r@0.25 e3@2/3 r@1/3 d3@0.5 r@0.5 e3@1.0 e3@1.75 r@1.25 c3@1/3 r@1/3 d3@1/3 e3@1/3 r@2/3 e3@2/3 e3@1/3 r@1/3 d3@1/3 c3@1.0 c3@2/3 r@2.0 e3@0.25 r@1/12 g3@2/3 a3@1/3 <end>\n",
      "Saving Output file as midi....\n",
      "Midi Sequnce in text\n",
      "<start> 130.0@tempo 4/4@time r@1.5 f#4@0.5 a4@0.5 a4@0.5 a4@0.25 f#4@0.25 e4@0.5 r@2.0 r@1.0 d4@0.5 d4@0.5 d4@0.5 e4@0.5 f#4@1.0 e4@0.5 c4@1.0 r@1.0 e4@0.5 d4@0.5 d4@0.5 e4@0.5 e4@0.5 e4@0.5 d4@0.5 r@1/6 r@1.0 e4@0.5 d4@0.5 d4@0.5 e4@0.5 e4@0.5 e4@0.5 d4@0.5 r@1/6 r@1.0 e4@0.5 d4@0.5 d4@0.5 e4@0.5 e4@0.5 e4@0.5 d4@0.5 r@1/6 r@1.0 e4@0.5 d4@0.5 d4@0.5 e4@0.5 e4@0.5 e4@0.5 d4@0.5 r@1/6 r@1.0 e4@0.5 d4@0.5 d4@0.5 e4@0.5 e4@0.5 e4@0.5 d4@0.5 r@1/6 r@1.0 e4@0.5 d4@0.5 d4@0.5 e4@0.5 e4@0.5 e4@0.5 d4@0.5 r@1/6 r@1.0 e4@0.5 d4@0.5 d4@0.5 e4@0.5 e4@0.5 e4@0.5 e4@0.5 d4@0.5 r@1/6 r@1.0 e4@0.5 d4@0.5 d4@0.5 e4@0.5 e4@0.5 e4@0.5 e4@0.5 d4@0.5 r@1/6 r@1.0 e4@0.5 d4@0.5 d4@0.5 e4@0.5 e4@0.5 e4@0.5 e4@0.5 d4@0.5 r@1/6 r@1.0 e4@0.5 d4@0.5 d4@0.5 e4@0.5 e4@0.5 e4@0.5 e4@0.5 d4@0.5 r@1/6 r@1.0 e4@0.5\n",
      "Saving Output file as midi....\n",
      "Midi Sequnce in text\n",
      "<start> 95.0@tempo 4/4@time r@0.5 d4@0.25 r@0.25 d4@0.25 r@0.25 e4@0.5 e4@0.5 e4@0.5 b3@0.25 r@0.25 d4@0.5 e4@0.5 b3@0.25 e4@0.25 r@0.25 d4@1.0 b3@1.0 a3@0.5 d4@0.25 r@0.25 d4@1.0 b3@1.0 a3@0.5 d4@0.25 r@0.25 d4@1.0 c4@1/3 a3@0.5 e4@0.25 r@0.25 a3@0.25 r@0.25 g3@2.0 a3@0.25 r@0.25 <end>\n",
      "Saving Output file as midi....\n",
      "Midi Sequnce in text\n",
      "<start> 118.0@tempo 4/4@time r@1.5 4@0.25 r@0.25 r@0.25 e3@0.25 e3@0.25 r@0.25 e3@0.25 r@0.25 g3@0.25 r@1/3 g3@1.0 r@1/6 0@0.25 r@0.25 c3@0.25 r@0.25 c3@0.25 c3@1/3 r@0.25 c3@0.25 r@1/6 d3@0.25 d3@13/12 r@5/12 d3@0.25 d3@0.25 d3@0.25 r@0.25 d3@0.25 d3@0.25 r@0.25 d3@0.25 r@0.25 f3@0.25 r@0.25 r@0.5 11@0.25 r@0.25 b2@0.25 r@0.25 b2@0.25 b2@1/3 r@0.25 b2@0.25 r@1/6 c3@0.25 c3@1.25 r@0.25 e3@0.25 e3@0.25 e3@0.25 r@0.25 e3@0.25 e3@0.25 r@0.25 e3@0.25 r@0.25 a3@0.25 a3@1/12 r@1.5 r@0.25 g3@1.25 0@0.25 r@5/12 r@2.25 c3@0.25 r@0.25 c3@0.25 c3@1/3 r@0.25 c3@0.25 r@1/6 d3@0.25 d3@13/12 r@5/12 2@0.25 r@0.25 d3@0.25 r@0.25 d3@0.25 d3@0.25 r@1/3 d3@0.25 r@1/6 f3@0.25 f3@1/12 r@0.25 f3@1.0 r@1/6 b2@0.25 b2@0.25 b2@0.25 r@0.25 b2@0.25 b2@0.25 r@0.25 b2@0.25 r@0.25 c3@0.25 <end>\n",
      "Saving Output file as midi....\n",
      "Midi Sequnce in text\n",
      "<start> 106.0@tempo 4/4@time r@0.5 a4@0.5 a4@0.5 a4@0.5 a4@0.5 e4@0.5 e4@0.5 d4@0.5 d4@0.5 e4@0.5 e4@0.5 r@2.5 r@0.5 f#4@0.5 f#4@0.5 f#4@0.5 f#4@0.5 d4@0.5 d4@0.5 b3@0.5 c4@0.5 r@0.5 b3@0.5 r@0.5 a3@0.5 r@0.5 e3@0.5 r@0.5 r@0.5 a4@0.5 a4@0.5 a4@0.5 a4@0.5 e4@0.5 e4@0.5 d4@0.5 d4@0.5 e4@0.5 e4@0.5 r@2.5 r@0.5 f#4@0.5 f#4@0.5 f#4@0.5 f#4@0.5 d4@0.5 d4@0.5 b3@0.5 c4@0.5 r@0.5 b3@0.5 r@0.5 a3@0.5 r@0.5 e3@0.5 r@0.5 <end>\n",
      "Saving Output file as midi....\n",
      "Midi Sequnce in text\n",
      "<start> 95.0@tempo 4/4@time r@0.5 e6@1.0 d6@1.0 d6@0.5 e6@0.75 d6@0.75 e6@0.5 e6@1/6 r@23/6 r@0.5 e4@0.5 e4@0.5 b3@0.25 r@2.75 b3@0.5 b3@0.25 d4@0.5 b3@0.25 r@1/3 b3@0.5 e4@0.5 g5@0.75 f4@0.25 r@0.5 b5@0.5 r@4.0 r@7/12 <end>\n",
      "Saving Output file as midi....\n",
      "Midi Sequnce in text\n",
      "<start> 136.0@tempo 4/4@time c4@0.25 r@0.75 c4@1.25 r@0.25 g3@0.25 r@0.25 g3@0.5 c4@0.25 r@0.25 e4@0.25 r@0.25 e4@0.25 r@0.25 c4@1/3 r@2/3 g3@1.25 r@0.25 g3@0.5 d4@0.25 r@0.25 d4@0.25 r@0.25 d4@1.0 r@0.5 a3@0.25 r@0.25 a3@0.5 d4@0.25 r@0.25 f4@0.5 r@0.5 e4@2/3 r@1/3 d4@0.5 c4@2/3 r@5/6 c4@1/3 r@2/3 c4@1.0 r@0.5 g3@0.25 r@0.25 g3@0.5 c4@0.25 r@0.25 e4@1/3 r@5/12 e4@0.5 r@0.25 c4@0.25 r@0.25 g3@1.0 r@0.5 g3@0.5 d4@0.25 r@0.25 d4@0.25 r@0.25 d4@1.0 r@0.5 a3@0.25 r@0.25 a3@0.5 d4@0.25 r@0.25 f4@0.5 r@0.5 e4@0.5 r@0.5 d4@0.5 c4@0.75 r@0.75 <end>\n",
      "Saving Output file as midi....\n",
      "Midi Sequnce in text\n",
      "<start> 95.0@tempo 4/4@time r@0.5 d4@0.25 r@0.25 c4@0.25 r@0.25 e4@0.5 e4@0.5 e4@0.5 b3@0.25 r@0.25 d4@0.5 b3@0.25 b3@0.25 r@0.25 b3@0.5 g3@0.25 b3@1.0 r@1.75 r@1.25 c4@0.25 d4@0.25 r@0.5 a3@0.5 r@0.5 b3@1.0 r@1.75 r@1.25 c4@0.25 d4@0.25 r@0.5 d4@1.0 b3@1.0 r@0.75 r@1.5 r@0.5 b4@1.0 r@1.0 b3@0.25 b3@0.5 b3@0.25 b4@0.25 r@0.25 e4@0.25 d4@0.25 c4@1.0 a3@0.25 r@0.5 d4@0.5 g3@0.25 g3@0.25 g3@0.25 c4@0.25 b3@0.25 r@0.25 c4@0.25 r@0.5 <end>\n",
      "Saving Output file as midi....\n",
      "Midi Sequnce in text\n",
      "<start> 128.0@tempo 4/4@time e5@1.5 d5@5/3 r@1/3 c5@0.5 a4@2.25 r@0.25 a4@0.5 e4@0.25 d4@0.25 c4@0.5 a4@0.25 r@0.25 a4@0.75 r@2.25 e4@0.25 d4@0.25 c4@1.25 r@2.75 r@0.5 g5@0.25 r@0.25 g5@0.5 e5@0.5 g5@0.25 r@0.25 g5@0.5 e5@0.25 r@0.25 e5@0.5 a5@0.5 a5@0.25 g5@0.25 r@0.25 g5@0.25 e5@0.25 r@0.25 e5@0.25 d5@0.5 c5@0.25 c5@0.5 a4@0.25 e4@0.25 a4@0.5 e4@0.5 a4@0.5 e4@0.25 d4@0.25 c4@0.5 g4@0.5 e4@0.25 d4@0.25 c4@0.5 a4@0.5 a4@0.5 r@0.5 e4@0.25 d4@0.25 c4@1.0 r@1.0 <end>\n",
      "Saving Output file as midi....\n",
      "Midi Sequnce in text\n",
      "<start> 119.1@tempo 4/4@time r@0.5 c5@0.25 r@0.25 c5@0.25 r@0.25 c5@0.25 r@0.25 c5@0.25 r@0.25 c5@0.25 r@0.25 c5@0.25 r@0.25 b4@0.25 r@0.25 b4@0.25 r@0.25 b4@0.25 r@0.25 c5@0.25 r@0.25 b4@0.75 r@0.25 b4@0.5 r@0.5 r@0.5 a4@0.25 r@0.25 a4@0.25 r@0.25 a4@0.25 r@0.25 a4@0.25 r@0.25 b4@0.25 r@0.25 c5@0.25 r@0.25 b4@0.25 r@0.25 b4@0.25 r@0.25 b4@0.25 r@0.25 c5@0.25 r@0.25 b4@0.75 r@0.25 b4@0.5 r@0.5 r@0.5 c5@0.25 r@0.25 c5@0.25 r@0.25 c5@0.25 r@0.25 c5@0.25 r@0.25 d5@0.25 r@0.25 c5@0.25 r@0.25 b4@0.25 r@0.25 b4@0.25 r@0.25 b4@0.25 r@0.25 c5@0.25 r@0.25 b4@0.75 r@0.25 b4@0.5 r@0.5 r@0.5 a4@0.25 r@0.25 a4@0.25 r@0.25 a4@0.25 r@0.25 g4@0.25 r@0.25 g4@0.25 r@0.25 a4@0.5 a4@0.25 r@0.25 b4@0.5 r@0.5 c5@0.25 r@0.25 c5@0.25 r@0.25 c5@0.25 r@0.25 c5@0.25 r@0.25 c5@0.25 r@0.25 d5@0.25 r@0.25 c5@0.25 r@0.25 b4@0.25 r@0.25 b4@0.25 r@0.25 b4@0.25 r@0.25 c5@0.25\n",
      "Saving Output file as midi....\n",
      "Midi Sequnce in text\n",
      "<start> 120.0@tempo 4/4@time e3@1.5 e3@2.5 r@2.0 e3@2/3 f3@2/3 g3@2/3 g3@1.5 f3@0.25 e3@0.25 f3@2.0 r@1.5 d3@0.5 d3@1.0 d3@1.0 d3@0.5 e3@1.0 e3@2.5 r@4.0 g3@0.5 f3@1.0 e3@2.5 r@2.0 e3@2/3 f3@2/3 g3@2/3 <end>\n",
      "Saving Output file as midi....\n",
      "Midi Sequnce in text\n",
      "<start> 119.1@tempo 4/4@time r@0.5 c5@0.25 r@0.25 c5@0.25 r@0.25 c5@0.25 r@0.25 c5@0.25 r@0.25 c5@0.25 r@0.25 c5@0.25 r@0.25 b4@0.25 r@0.25 b4@0.25 r@0.25 b4@0.25 r@0.25 c5@0.25 r@0.25 b4@0.75 r@0.25 b4@0.5 r@0.5 r@0.5 a4@0.25 r@0.25 a4@0.25 r@0.25 a4@0.25 r@0.25 a4@0.25 r@0.25 b4@0.25 r@0.25 c5@0.25 r@0.25 b4@0.25 r@0.25 b4@0.25 r@0.25 b4@0.25 r@0.25 c5@0.25 r@0.25 b4@0.75 r@0.25 b4@0.5 r@0.5 r@0.5 c5@0.25 r@0.25 c5@0.25 r@0.25 c5@0.25 r@0.25 c5@0.25 r@0.25 d5@0.25 r@0.25 c5@0.25 r@0.25 b4@0.25 r@0.25 b4@0.25 r@0.25 b4@0.25 r@0.25 c5@0.25 r@0.25 b4@0.75 r@0.25 b4@0.5 r@0.5 r@0.5 a4@0.25 r@0.25 a4@0.25 r@0.25 a4@0.25 r@0.25 g4@0.25 r@0.25 g4@0.25 r@0.25 a4@0.5 a4@0.25 r@0.25 b4@0.5 r@0.5 c5@0.25 r@0.25 c5@0.25 r@0.25 c5@0.25 r@0.25 c5@0.25 r@0.25 c5@0.25 r@0.25 d5@0.25 r@0.25 c5@0.25 r@0.25 b4@0.25 r@0.25 b4@0.25 r@0.25 b4@0.25 r@0.25 c5@0.25\n",
      "Saving Output file as midi....\n",
      "Midi Sequnce in text\n",
      "<start> 125.0@tempo 4/4@time r@1.5 g3@0.5 a4@0.5 r@0.5 c5@0.5 r@0.5 c5@0.5 e4@0.5 c5@0.5 d5@5/3 r@0.5 g4@1.0 e4@0.5 c5@0.5 d5@5/3 r@0.5 c5@1.0 c5@4.0 c5@1.0 r@1.0 g4@1.0 a4@0.5 r@0.5 c5@0.5 d5@0.5 e4@0.5 d5@5/3 r@2.25 r@0.5 e4@0.5 c5@0.5 c5@0.5 d5@0.5 e4@0.5 d5@5/3 r@0.5 r@0.5 d5@5/3 r@0.5 c5@1.25 <end>\n",
      "Saving Output file as midi....\n",
      "Midi Sequnce in text\n",
      "<start> 95.0@tempo 4/4@time r@0.5 c5@0.25 r@0.25 c5@0.25 r@0.25 c5@0.25 r@0.25 c5@0.25 r@0.25 c5@0.25 r@0.25 b4@0.25 r@0.25 b4@0.25 r@0.25 b4@0.25 r@0.25 c5@0.25 r@0.25 b4@0.75 r@0.25 b4@0.5 r@0.5 r@0.5 a4@0.25 r@0.25 a4@0.25 r@0.25 a4@0.25 r@0.25 a4@0.25 r@0.25 b4@0.25 r@0.25 c5@0.25 r@0.25 b4@0.25 r@0.25 b4@0.25 r@0.25 b4@0.25 r@0.25 c5@0.25 r@0.25 b4@0.75 r@0.25 b4@0.5 r@0.5 r@0.5 c5@0.25 r@0.25 c5@0.25 r@0.25 c5@0.25 r@0.25 c5@0.25 r@0.25 b4@0.25 r@0.25 b4@0.25 r@0.25 b4@0.25 r@0.25 c5@0.25 r@0.25 b4@0.75 r@0.25 b4@0.5 r@0.5 r@0.5 a4@0.25 r@0.25 a4@0.25 r@0.25 a4@0.25 r@0.25 a4@0.25 r@0.25 g4@0.25 r@0.25 g4@0.25 r@0.25 a4@0.5 a4@0.25 r@0.25 b4@0.5 r@0.5 b4@0.25 r@0.25 a4@0.5 g4@0.25 r@0.25 a4@0.25 r@0.25 b4@0.25 r@0.25 <end>\n",
      "Saving Output file as midi....\n",
      "Midi Sequnce in text\n",
      "<start> 100.0@tempo 4/4@time r@2.5 a5@0.5 d6@0.25 r@1/6 e6@0.25 e6@0.25 r@0.25 0.2@0.25 r@0.25 d6@0.25 r@0.25 a5@0.25 c6@0.25 r@0.25 c6@0.25 r@0.25 d6@0.25 r@0.5 a5@0.25 9.0@0.25 r@0.5 c6@0.25 c6@0.25 r@0.25 g5@1/3 r@1/12 a5@0.25 r@1/3 a5@0.25 r@0.25 a5@0.25 r@1.0 4@1/3 e6@0.25 r@1/6 e6@0.25 r@0.25 a5@0.25 r@0.25 c6@0.25 r@0.25 r@1/12 d6@1/3 r@0.5 a5@0.25 a5@0.25 c6@0.25 r@0.25 r@0.25 <end>\n",
      "Saving Output file as midi....\n",
      "Midi Sequnce in text\n",
      "<start> 130.0@tempo 4/4@time c-1@0.25 r@1.75 c-1@0.25 r@1.75 c-1@0.25 r@1.75 c-1@0.25 r@1.75 c-1@0.25 r@2.0 r@0.75 c5@0.5 d5@2/3 e5@2/3 r@1/3 d5@2/3 r@1/3 c5@0.5 r@1/3 b4@0.5 r@0.5 a4@0.75 b4@1/6 r@3.25 r@1.0 r@2.0 c5@0.5 d5@2/3 e5@2/3 r@1/3 d5@0.5 r@4/3 c5@0.5 d5@0.5 c5@1.0 d5@1/6 a4@0.75 r@2.25 r@1.0 r@1.5 c5@2/3 d5@0.5 r@1/3 e5@2/3 r@0.5 d5@2/3 r@1/3 c5@0.5 r@5/6 d5@0.5 c5@0.75 r@2.5 d5@1/6 b4@2/3 r@0.25 a4@1.0 b4@1.0 r@7/12 a4@0.75 r@0.5 <end>\n",
      "Saving Output file as midi....\n",
      "Midi Sequnce in text\n",
      "<start> 130.0@tempo 4/4@time r@1.5 g3@0.5 c4@0.5 c4@1.0 c4@1.0 e3@0.25 a3@0.25 e3@0.25 g3@0.5 d3@0.5 e3@0.25 r@0.25 d3@0.5 e3@0.25 r@0.25 g3@0.25 r@2.5 e4@0.25 r@0.25 g3@0.5 b3@0.25 r@0.25 e3@0.25 g3@0.5 g3@0.25 r@0.25 a3@0.25 r@0.25 g3@0.25 b3@0.25 g3@0.25 r@0.25 g3@0.25 b3@0.25 g3@0.25 r@0.25 g3@0.5 c4@0.25 r@0.25 g3@0.25 r@0.25 g3@0.25 r@0.25 r@1.5 g3@0.5 e4@0.5 e4@0.5 e4@0.25 r@0.25 r@1.5 e4@0.25 r@0.25 r@1.5 r@1.5 e4@0.5 r@0.25 b3@0.5 r@0.25 <end>\n",
      "Saving Output file as midi....\n",
      "Midi Sequnce in text\n",
      "<start> 183.0@tempo 4/4@time r@2.0 g4@1.0 a4@0.5 r@0.5 c5@0.5 r@0.5 c5@0.5 d5@5/3 e5@0.75 r@0.25 d5@1.5 e5@1.5 d5@0.5 r@0.5 c5@4.0 c5@1.0 r@1.0 g4@1.0 a4@0.5 r@0.5 c5@0.5 r@0.5 c5@0.5 d5@5/3 e5@0.75 r@0.25 d5@1.5 e5@1.5 d5@0.5 r@0.5 c5@4.0 <end>\n",
      "Saving Output file as midi....\n",
      "Midi Sequnce in text\n",
      "<start> 95.0@tempo 4/4@time r@0.5 e6@1.0 d6@1.0 b5@0.5 d6@0.5 d6@0.5 b5@1.5 e3@1.0 r@4.0 b3@0.5 b3@0.25 r@2.25 b5@0.5 b5@0.5 r@1.0 g5@0.5 d3@1.0 c3@0.5 e5@0.5 r@2.5 r@0.5 <end>\n",
      "Saving Output file as midi....\n",
      "Midi Sequnce in text\n",
      "<start> 4/4@time e6@0.25 e6@0.25 e6@0.25 e6@0.25 d6@0.5 d6@0.5 a5@0.5 a5@0.5 c6@0.5 d6@0.5 r@0.5 g5@0.25 g5@0.25 b5@0.5 c6@0.5 b5@0.5 g5@0.5 e5@0.5 e5@0.5 e6@0.25 e6@0.25 e6@0.25 e6@0.25 d6@0.5 g6@0.5 a5@0.5 a5@0.5 c6@0.5 d6@0.5 r@0.5 g5@0.25 g5@0.25 b5@0.5 c6@0.5 b5@0.5 g5@0.5 e5@0.5 e5@0.5 e6@0.25 e6@0.25 e6@0.25 e6@0.25 d6@0.5 g6@0.5 a5@0.5 a5@0.5 c6@0.5 d6@0.5 r@0.5 g5@0.25 g5@0.25 b5@0.5 c6@0.5 b5@0.5 g5@0.5 e5@0.5 e5@0.5 e6@0.25 e6@0.25 e6@0.25 e6@0.25 d6@0.5 g6@0.5 a5@0.5 a5@0.5 c6@0.5 d6@0.5 r@0.5 g5@0.25 g5@0.25 b5@0.5 c6@0.5 b5@0.5 g5@0.5 e5@0.5 e5@0.5 e6@0.25 e6@0.25 e6@0.25 e6@0.25 d6@0.5 g6@0.5 a5@0.5 a5@0.5 c6@0.5 d6@0.5 r@0.5 g5@0.25 g5@0.25 b5@0.5 c6@0.5 b5@0.5 g5@0.5 e5@0.5 e5@0.5 e6@0.25 e6@0.25 e6@0.25 e6@0.25 d6@0.5 g6@0.5 a5@0.5 a5@0.5 c6@0.5 d6@0.5 r@0.5 g5@0.25 g5@0.25 b5@0.5 c6@0.5 b5@0.5 g5@0.5 e5@0.5\n",
      "Saving Output file as midi....\n",
      "Midi Sequnce in text\n",
      "<start> 64.0@tempo 4/4@time r@0.25 r@1/3 g4@0.25 g4@0.25 r@0.25 r@1.75 e4@0.25 f4@0.25 e4@0.25 d4@0.25 c4@0.25 r@0.25 g4@0.25 g4@0.25 r@0.25 r@17/12 e4@0.25 f4@0.25 e4@0.25 d4@1/3 r@1/6 r@0.5 g4@0.25 e4@0.25 f4@0.25 e4@0.25 d4@0.25 c4@0.25 c4@0.75 b4@0.25 c5@1.0 c4@0.75 b4@0.25 c5@0.25 c4@0.25 d4@0.25 e4@0.25 c4@1/3 r@19/6 d4@0.25 c4@0.25 <end>\n",
      "Saving Output file as midi....\n",
      "Midi Sequnce in text\n",
      "<start> 125.0@tempo 4/4@time r@0.5 c5@0.25 c5@0.25 d4@0.25 r@0.25 e4@0.25 r@0.25 e4@0.5 e4@0.25 f4@0.25 e4@0.25 d4@0.25 c4@0.25 r@0.25 d4@0.25 e4@0.25 d4@0.25 c4@0.25 a3@0.25 b3@0.25 r@0.25 g4@0.25 g4@0.25 e4@0.25 f4@0.25 e4@0.25 d4@0.25 c4@0.25 r@0.25 g4@0.25 g4@0.25 e4@0.25 f4@0.25 e4@0.25 d4@0.25 c4@0.25 c4@0.75 r@0.25 c4@0.25 c4@0.5 d4@0.5 c4@0.5 d4@0.25 g4@0.25 a4@0.25 b4@0.25 r@0.25 r@0.25 e4@0.5 e4@0.5 c4@0.75 r@1.25 <end>\n",
      "Saving Output file as midi....\n",
      "Midi Sequnce in text\n",
      "<start> 119.1@tempo 4/4@time r@0.5 c5@0.25 r@0.25 c5@0.25 r@0.25 c5@0.25 r@0.25 c5@0.25 r@0.25 c5@0.25 r@0.25 c5@0.25 r@0.25 b4@0.25 r@0.25 b4@0.25 r@0.25 b4@0.25 r@0.25 c5@0.25 r@0.25 b4@0.75 r@0.25 b4@0.5 r@0.5 r@0.5 a4@0.25 r@0.25 a4@0.25 r@0.25 a4@0.25 r@0.25 a4@0.25 r@0.25 b4@0.25 r@0.25 c5@0.25 r@0.25 b4@0.25 r@0.25 b4@0.25 r@0.25 b4@0.25 r@0.25 c5@0.25 r@0.25 b4@0.75 r@0.25 b4@0.5 r@0.5 r@0.5 c5@0.25 r@0.25 c5@0.25 r@0.25 c5@0.25 r@0.25 c5@0.25 r@0.25 d5@0.25 r@0.25 c5@0.25 r@0.25 b4@0.25 r@0.25 b4@0.25 r@0.25 b4@0.25 r@0.25 c5@0.25 r@0.25 b4@0.75 r@0.25 b4@0.5 r@0.5 r@0.5 a4@0.25 r@0.25 a4@0.25 r@0.25 a4@0.25 r@0.25 g4@0.25 r@0.25 g4@0.25 r@0.25 a4@0.5 a4@0.25 r@0.25 b4@0.5 r@0.5 c5@0.25 r@0.25 c5@0.25 r@0.25 c5@0.25 r@0.25 c5@0.25 r@0.25 c5@0.25 r@0.25 d5@0.25 r@0.25 c5@0.25 r@0.25 b4@0.25 r@0.25 b4@0.25 r@0.25 b4@0.25 r@0.25 c5@0.25\n",
      "Saving Output file as midi....\n",
      "Midi Sequnce in text\n",
      "<start> 106.0@tempo 4/4@time r@0.5 a4@0.5 a4@0.5 a4@0.5 a4@0.5 e4@0.5 e4@0.5 d4@0.5 d4@0.5 e4@0.5 e4@0.5 r@2.5 r@0.5 f#4@0.5 f#4@0.5 f#4@0.5 f#4@0.5 d4@0.5 d4@0.5 b3@0.5 c4@0.5 r@0.5 b3@0.5 r@0.5 a3@0.5 r@0.5 e3@0.5 r@0.5 r@0.5 a4@0.5 a4@0.5 a4@0.5 a4@0.5 e4@0.5 e4@0.5 d4@0.5 d4@0.5 e4@0.5 e4@0.5 r@2.5 r@0.5 f#4@0.5 f#4@0.5 f#4@0.5 f#4@0.5 d4@0.5 d4@0.5 b3@0.5 c4@0.5 r@0.5 b3@0.5 r@0.5 a3@0.5 r@0.5 e3@0.5 r@0.5 <end>\n",
      "Saving Output file as midi....\n",
      "Midi Sequnce in text\n",
      "<start> 70.0@tempo 4/4@time r@3.25 d4@0.5 c4@0.25 c4@0.5 e4@0.5 g4@0.5 b4@0.5 c5@0.5 9.11@0.25 g4@0.25 a4@0.5 g4@0.5 r@0.5 d5@0.75 c5@0.25 c5@0.5 b4@0.5 c5@0.5 9.11@0.25 r@1/12 7.9@0.25 r@1/6 g4@0.25 r@0.5 f4@0.25 a4@0.25 c5@0.5 d5@0.25 e5@0.75 d5@0.5 c5@0.25 a4@0.75 r@0.5 e5@0.25 g5@0.25 e5@0.25 g4@0.25 r@0.5 g4@0.25 e5@0.75 g4@0.25 r@0.5 g4@0.25 a4@0.25 e5@0.25 b2@0.5 g4@0.25 r@1/6 g4@0.25 r@0.5 g4@0.25 a4@0.25 c5@0.5 g5@0.5 g5@0.5 f5@0.75 2.4.5@0.25 c5@0.5 <end>\n",
      "Saving Output file as midi....\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "#load tokenizer from pickle\n",
    "tokenizer = load(open(data_dir + 'tokenizer.pkl', 'rb'))\n",
    "#load best model\n",
    "model = create_Model(vocabSize, maxLength)\n",
    "model.load_weights(filepath)\n",
    "\n",
    "images = glob(data_dir + 'testImages/*.jpg')\n",
    "for img in images:\n",
    "    photo = extract_featuresPredict(img)\n",
    "    #generate midi\n",
    "    midiSequence, prediction_output = generate_midiSequence(model, tokenizer, photo, maxLength)\n",
    "\n",
    "    print(\"Midi Sequnce in text\")\n",
    "    print(midiSequence)\n",
    "\n",
    "    #create midi file\n",
    "    create_midi(prediction_output, img.split('.')[0].rsplit('\\\\')[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evalution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to calculate average tone span (semitones between lowest and highest note in the melody)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTonespan(testingSongs):\n",
    "    scale = {\"C\": 0, \"C#\": 1, \"D-\" : 1, \"D\" : 2, 'D#' : 3, \"E-\": 3, \"E\" : 4, \"F-\": 4, \"E#\" : 5, \"F\" : 5, \"F#\" : 6, \"G-\" : 6, \"G\" : 7, \n",
    "             \"G#\": 8, \"A-\": 8, \"A\": 9, \"A#\": 10, \"B-\": 10, \"B\": 11, \"C-\":11, \"B#\": 12 }\n",
    "    tonespans = []\n",
    "    for file in testingSongs:\n",
    "        #print(file)\n",
    "        try:\n",
    "            midi = converter.parse(file) #convert to midi\n",
    "        except:\n",
    "            print(\"Error in parsing \" + str(file))\n",
    "            continue\n",
    "        #tranpose song\n",
    "        try:\n",
    "            midi = transpose(midi)\n",
    "        except:\n",
    "            print(\"Error in obtaining key for \" + str(file))\n",
    "            continue\n",
    "        startBar = getStartingBar(midi)\n",
    "        midi = midi.measures(startBar, startBar + 7)\n",
    "        midi = midi.flat\n",
    "        minNote = {\"value\": float('inf'), \"name\": ''}\n",
    "        minOct = float('inf')\n",
    "        maxNote = {\"value\": float('-inf'), \"name\": ''}\n",
    "        maxOct = float('-inf')\n",
    "        for event in midi:\n",
    "            if isinstance(event, note.Note):\n",
    "                if(int(str(event.pitch)[-1]) < minOct):\n",
    "                    minOct = int(str(event.pitch)[-1])\n",
    "                if(int(str(event.pitch)[-1]) > maxOct):\n",
    "                    maxOct = int(str(event.pitch)[-1])\n",
    "        #print(\"Min : \" + str(minOct) + \" Max: \" + str(maxOct))\n",
    "        for event in midi:\n",
    "            if isinstance(event, note.Note):\n",
    "                if(int(str(event.pitch)[-1]) == minOct):\n",
    "                    if( scale[str(event.pitch)[:-1]] < minNote[\"value\"]):\n",
    "                        minNote[\"value\"] = scale[str(event.pitch)[:-1]] \n",
    "                        minNote[\"name\"] = event\n",
    "                if(int(str(event.pitch)[-1]) == maxOct):\n",
    "                    if( scale[str(event.pitch)[:-1]] > maxNote[\"value\"]):\n",
    "                        maxNote[\"value\"] = scale[str(event.pitch)[:-1]] \n",
    "                        maxNote[\"name\"] = event\n",
    "        #print(\"MinNote: \" + str(minNote[\"value\"]) + \" name: \" + str(minNote[\"name\"].pitch))\n",
    "        #print(\"MaxNote: \" + str(maxNote[\"value\"]) + \" name: \" + str(maxNote[\"name\"].pitch))\n",
    "\n",
    "        semitones = interval.Interval(minNote[\"name\"], maxNote[\"name\"]).semitones\n",
    "        #print(\"semitones: \" + str(semitones))\n",
    "        tonespans.append(int(semitones))\n",
    "\n",
    "    avg = sum(tonespans)/len(tonespans)\n",
    "    return avg\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate avg tonespan for all midi files in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg tone span in dataset: 11.883333333333333\n"
     ]
    }
   ],
   "source": [
    "datasetSongs = glob(data_dir + 'midi/*.mid')\n",
    "print(\"Avg tone span in dataset: \" + str(getTonespan(datasetSongs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate avg tonespan for a sample of 16 midi files generated from the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg tone span in dataset: 16.533333333333335\n"
     ]
    }
   ],
   "source": [
    "testingSongs = glob(data_dir + 'testing/*.mid')\n",
    "print(\"Avg tone span in dataset: \" + str(getTonespan(testingSongs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to calculate the scale consistency of a set of midi files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAvgScaleConsistency(testingSongs):\n",
    "    A_minor = [\"A\", \"B\", \"C\", \"D\", 'E', \"F\", \"G#\"]\n",
    "    C_major = [\"C\", \"D\", \"E\", \"F\", 'G', \"A\", \"B\"]\n",
    "\n",
    "    allRatios = []\n",
    "\n",
    "    for file in testingSongs:\n",
    "        try: \n",
    "            midi = converter.parse(file) #convert to midi\n",
    "        except:\n",
    "            print(\"Error in parsing \" + str(file))\n",
    "            continue\n",
    "        #tranpose song\n",
    "        try:\n",
    "            midi = transpose(midi)\n",
    "        except:\n",
    "            print(\"Error in obtaining key for \" + str(file))\n",
    "            continue\n",
    "\n",
    "        startBar = getStartingBar(midi)\n",
    "        midi = midi.measures(startBar, startBar + 7)\n",
    "        midi = midi.flat\n",
    "\n",
    "        correctNotes = 0\n",
    "        FG_list = []\n",
    "        GF_list = []\n",
    "        totNotes = 0\n",
    "        key = midi.analyze(\"key\")\n",
    "        if key.mode == \"major\":\n",
    "            for event in midi:\n",
    "                if isinstance(event, note.Note):\n",
    "                    totNotes += 1\n",
    "                    if (str(event.pitch)[:-1] in C_major):\n",
    "                                correctNotes += 1\n",
    "        elif key.mode == \"minor\":\n",
    "            for event in midi:\n",
    "                if isinstance(event, note.Note):\n",
    "                    totNotes += 1\n",
    "                    if((str(event.pitch)[:-1] == \"F#\") & (len(FG_list) == 0)):\n",
    "                        FG_list.append(\"F#\")\n",
    "                        continue\n",
    "                    if(str(event.pitch)[:-1] == \"G#\"):\n",
    "                        if(len(FG_list) == 1):\n",
    "                            if(FG_list[0] == \"F#\"):\n",
    "                                correctNotes += 2\n",
    "                                FG_list = []\n",
    "                                continue\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                    if((str(event.pitch)[:-1] == \"G\")  & (len(GF_list) == 0)):\n",
    "                        GF_list.append(\"G\")\n",
    "                        continue\n",
    "                    if(str(event.pitch)[:-1] == \"F\"):\n",
    "                        if(len(FG_list) == 1):\n",
    "                            if(FG_list[0] == \"G\"):\n",
    "                                correctNotes += 2\n",
    "                                GF_list = []\n",
    "                                continue\n",
    "\n",
    "\n",
    "                    if (str(event.pitch)[:-1] in A_minor):\n",
    "                        correctNotes += 1\n",
    "\n",
    "        allRatios.append(correctNotes/totNotes)\n",
    "\n",
    "    print(\"Final avg scale consistency percentage : \" + str(sum(allRatios)/len(allRatios) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate scale consistency of original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final avg scale consistency percentage : 95.35331443422385\n"
     ]
    }
   ],
   "source": [
    "testingSongs = glob(data_dir + 'midi/*.mid')\n",
    "getAvgScaleConsistency(testingSongs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate scale consistency of testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final avg scale consistency percentage : 96.23026037490698\n"
     ]
    }
   ],
   "source": [
    "testingSongs = glob(data_dir + 'testing/*.mid')\n",
    "getAvgScaleConsistency(testingSongs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "HEg9f6j9CTJt"
   ],
   "name": "Prototype1.0.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
